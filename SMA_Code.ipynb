{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T6sEhoTFDEH3"
   },
   "source": [
    "## å®‰è£å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2V9shIFDDG3J",
    "outputId": "72d8024f-64c8-41fc-8ca0-00a5bffe1574"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (0.42.1)\n",
      "Requirement already satisfied: emoji in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (2.14.1)\n",
      "Requirement already satisfied: langdetect in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (1.0.9)\n",
      "Requirement already satisfied: six in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: datasets in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (2.12.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=8.0.0 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (16.1.0)\n",
      "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
      "Requirement already satisfied: pandas in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (4.66.5)\n",
      "Requirement already satisfied: xxhash in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
      "Requirement already satisfied: multiprocess in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
      "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (2023.4.0)\n",
      "Requirement already satisfied: aiohttp in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (3.10.5)\n",
      "Requirement already satisfied: huggingface-hub<1.0.0,>=0.11.0 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (0.15.1)\n",
      "Requirement already satisfied: packaging in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (24.1)\n",
      "Requirement already satisfied: responses<0.19 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (0.13.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.18.0)\n",
      "Requirement already satisfied: filelock in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0.0,>=0.11.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.19)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.12.14)\n",
      "Requirement already satisfied: six in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from responses<0.19->datasets) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (from yarl<2.0,>=1.0->aiohttp->datasets) (0.2.0)\n",
      "Requirement already satisfied: lingua-language-detector in /Users/zhuotingzhen/anaconda3/lib/python3.11/site-packages (2.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install jieba\n",
    "!pip install emoji langdetect\n",
    "!pip install datasets\n",
    "!pip install lingua-language-detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vhtPvgrLCUzp",
    "outputId": "1ecc2382-688c-437a-bc60-6b7a4ea45862"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: jieba in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (0.42.1)\n",
      "Requirement already satisfied: emoji in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.14.1)\n",
      "Requirement already satisfied: langdetect in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.0.9)\n",
      "Requirement already satisfied: pytz in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2024.1)\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.7.0)\n",
      "Requirement already satisfied: lingua-language-detector in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (2.1.0)\n",
      "Requirement already satisfied: datasets in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.6.0)\n",
      "Requirement already satisfied: openpyxl in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: six in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (1.26.4)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (20.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (2.2.1)\n",
      "Requirement already satisfied: requests>=2.32.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (0.31.1)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: et-xmlfile in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.18)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub>=0.24.0->datasets) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests>=2.32.2->datasets) (2025.4.26)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install jieba emoji langdetect pytz torch lingua-language-detector datasets openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8HGttCcMDKE0"
   },
   "source": [
    "## å¼•å…¥å¥—ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.51.3-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (0.31.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Using cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->transformers) (2025.4.26)\n",
      "Downloading transformers-4.51.3-py3-none-any.whl (10.4 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m10.4/10.4 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
      "Downloading safetensors-0.5.3-cp38-abi3-macosx_11_0_arm64.whl (418 kB)\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: safetensors, regex, tokenizers, transformers\n",
      "Successfully installed regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 transformers-4.51.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip3 install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "JQ6rzOpBTI5K"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import jieba\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "import numpy as np\n",
    "\n",
    "import re\n",
    "import emoji\n",
    "import langdetect\n",
    "from langdetect import detect\n",
    "from lingua import LanguageDetectorBuilder, Language, IsoCode639_1\n",
    "from datetime import datetime\n",
    "import pytz\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zM7PgPNTPXMd",
    "outputId": "ca72f2aa-3135-4a1f-857e-ea5f956efe1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# è¨­å®šå¥½è·¯å¾‘ (å¾Œé¢éƒ½æ˜¯ä½¿ç”¨ç›¸å°è·¯å¾‘)\n",
    "base_path = '/content/drive/My Drive/SMA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "id": "xOIyJJ3KSNT9",
    "outputId": "e38e0262-6047-4c2a-c225-454cac6940d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>post_time</th>\n",
       "      <th>topic</th>\n",
       "      <th>time_info</th>\n",
       "      <th>content</th>\n",
       "      <th>has_photo</th>\n",
       "      <th>has_video</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>share_count</th>\n",
       "      <th>view_count</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>post_url</th>\n",
       "      <th>scrape_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>2025-04-29T10:58:39.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3å°æ™‚</td>\n",
       "      <td>Thank you God for another day.</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>190</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3,197</td>\n",
       "      <td>141073</td>\n",
       "      <td>https://www.threads.net/@ayofvr/post/DJBymf8uTrK</td>\n",
       "      <td>2025-04-29T22:27:40.176749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-29T12:33:44.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1å°æ™‚</td>\n",
       "      <td>ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>196</td>\n",
       "      <td>16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>3Â è¬</td>\n",
       "      <td>77683</td>\n",
       "      <td>https://www.threads.net/@ban.mei.onnnnni/post/...</td>\n",
       "      <td>2025-04-29T22:27:54.964788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ribboworld2021</td>\n",
       "      <td>2025-04-29T04:39:46.000Z</td>\n",
       "      <td>å°ä¸€æ—¥å¸¸</td>\n",
       "      <td>9å°æ™‚</td>\n",
       "      <td>è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4,559</td>\n",
       "      <td>99</td>\n",
       "      <td>https://www.threads.net/@ribboworld2021/post/D...</td>\n",
       "      <td>2025-04-29T22:28:09.873641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>2025-04-29T11:25:22.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3å°æ™‚</td>\n",
       "      <td>Just be strong. Confident. Hopeful. Intellectu...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1,967</td>\n",
       "      <td>141093</td>\n",
       "      <td>https://www.threads.net/@ayofvr/post/DJB1qP5OmzP</td>\n",
       "      <td>2025-04-29T22:28:24.726576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jose_ykc</td>\n",
       "      <td>2025-04-29T10:36:19.000Z</td>\n",
       "      <td>è¼”ä»å¤§å­¸</td>\n",
       "      <td>3å°æ™‚</td>\n",
       "      <td>æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>4,334</td>\n",
       "      <td>55</td>\n",
       "      <td>513</td>\n",
       "      <td>2,460</td>\n",
       "      <td>10Â è¬</td>\n",
       "      <td>65</td>\n",
       "      <td>https://www.threads.net/@jose_ykc/post/DJBvpGI...</td>\n",
       "      <td>2025-04-29T22:28:39.393706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>leighton.williams</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 07:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8å°æ™‚</td>\n",
       "      <td>First tasting in California</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>726</td>\n",
       "      <td>30</td>\n",
       "      <td>https://www.threads.net/@leighton.williams/pos...</td>\n",
       "      <td>2025-04-29T16:23:40.328046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>cape__man</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9å°æ™‚</td>\n",
       "      <td>I hoped it would have been better.</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1,291</td>\n",
       "      <td>114</td>\n",
       "      <td>https://www.threads.net/@cape__man/post/DJAdFd...</td>\n",
       "      <td>2025-04-29T16:23:55.063517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>simimoonlight</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9å°æ™‚</td>\n",
       "      <td>I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>2,656</td>\n",
       "      <td>29</td>\n",
       "      <td>280</td>\n",
       "      <td>47</td>\n",
       "      <td>5.6Â è¬</td>\n",
       "      <td>65732</td>\n",
       "      <td>https://www.threads.net/@simimoonlight/post/DJ...</td>\n",
       "      <td>2025-04-29T16:24:39.870994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>other98</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 12:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3å°æ™‚</td>\n",
       "      <td>Tonight, Canada just proved that they have a h...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0Â è¬</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>22</td>\n",
       "      <td>14Â è¬</td>\n",
       "      <td>217182</td>\n",
       "      <td>https://www.threads.net/@other98/post/DJBGV3NxiX_</td>\n",
       "      <td>2025-04-29T16:24:54.669936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>scottiebeam</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 01:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14å°æ™‚</td>\n",
       "      <td>Yall be fighting on here â€¦ i thought threads w...</td>\n",
       "      <td>N</td>\n",
       "      <td>N</td>\n",
       "      <td>427</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>1Â è¬</td>\n",
       "      <td>59249</td>\n",
       "      <td>https://www.threads.net/@scottiebeam/post/DI_6...</td>\n",
       "      <td>2025-04-29T16:25:09.396585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3101 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                 post_time topic time_info  \\\n",
       "0                ayofvr  2025-04-29T10:58:39.000Z   NaN       3å°æ™‚   \n",
       "1                   NaN  2025-04-29T12:33:44.000Z   NaN       1å°æ™‚   \n",
       "2        ribboworld2021  2025-04-29T04:39:46.000Z  å°ä¸€æ—¥å¸¸       9å°æ™‚   \n",
       "3                ayofvr  2025-04-29T11:25:22.000Z   NaN       3å°æ™‚   \n",
       "4              jose_ykc  2025-04-29T10:36:19.000Z  è¼”ä»å¤§å­¸       3å°æ™‚   \n",
       "...                 ...                       ...   ...       ...   \n",
       "3096  leighton.williams         2025å¹´04æœˆ29æ—¥ 07:30   NaN       8å°æ™‚   \n",
       "3097          cape__man         2025å¹´04æœˆ29æ—¥ 06:31   NaN       9å°æ™‚   \n",
       "3098      simimoonlight         2025å¹´04æœˆ29æ—¥ 06:26   NaN       9å°æ™‚   \n",
       "3099            other98         2025å¹´04æœˆ29æ—¥ 12:31   NaN       3å°æ™‚   \n",
       "3100        scottiebeam         2025å¹´04æœˆ29æ—¥ 01:33   NaN      14å°æ™‚   \n",
       "\n",
       "                                                content has_photo has_video  \\\n",
       "0                        Thank you God for another day.         N         N   \n",
       "1                                      ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼         Y         N   \n",
       "2              è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€         N         N   \n",
       "3     Just be strong. Confident. Hopeful. Intellectu...         N         N   \n",
       "4                             æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€         Y         Y   \n",
       "...                                                 ...       ...       ...   \n",
       "3096                        First tasting in California         N         N   \n",
       "3097                 I hoped it would have been better.         N         N   \n",
       "3098  I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...         N         N   \n",
       "3099  Tonight, Canada just proved that they have a h...         N         N   \n",
       "3100  Yall be fighting on here â€¦ i thought threads w...         N         N   \n",
       "\n",
       "     like_count reply_count repost_count share_count view_count  \\\n",
       "0           190           3           23         NaN      3,197   \n",
       "1           196          16          NaN           6        3Â è¬   \n",
       "2            75           6          NaN         NaN      4,559   \n",
       "3            83           5            3           1      1,967   \n",
       "4         4,334          55          513       2,460       10Â è¬   \n",
       "...         ...         ...          ...         ...        ...   \n",
       "3096          7         NaN          NaN           0        726   \n",
       "3097          2         NaN          NaN           0      1,291   \n",
       "3098      2,656          29          280          47      5.6Â è¬   \n",
       "3099      1.0Â è¬         214          214          22       14Â è¬   \n",
       "3100        427          76           28           1        1Â è¬   \n",
       "\n",
       "      followers_count                                           post_url  \\\n",
       "0              141073   https://www.threads.net/@ayofvr/post/DJBymf8uTrK   \n",
       "1               77683  https://www.threads.net/@ban.mei.onnnnni/post/...   \n",
       "2                  99  https://www.threads.net/@ribboworld2021/post/D...   \n",
       "3              141093   https://www.threads.net/@ayofvr/post/DJB1qP5OmzP   \n",
       "4                  65  https://www.threads.net/@jose_ykc/post/DJBvpGI...   \n",
       "...               ...                                                ...   \n",
       "3096               30  https://www.threads.net/@leighton.williams/pos...   \n",
       "3097              114  https://www.threads.net/@cape__man/post/DJAdFd...   \n",
       "3098            65732  https://www.threads.net/@simimoonlight/post/DJ...   \n",
       "3099           217182  https://www.threads.net/@other98/post/DJBGV3NxiX_   \n",
       "3100            59249  https://www.threads.net/@scottiebeam/post/DI_6...   \n",
       "\n",
       "                     scrape_time  \n",
       "0     2025-04-29T22:27:40.176749  \n",
       "1     2025-04-29T22:27:54.964788  \n",
       "2     2025-04-29T22:28:09.873641  \n",
       "3     2025-04-29T22:28:24.726576  \n",
       "4     2025-04-29T22:28:39.393706  \n",
       "...                          ...  \n",
       "3096  2025-04-29T16:23:40.328046  \n",
       "3097  2025-04-29T16:23:55.063517  \n",
       "3098  2025-04-29T16:24:39.870994  \n",
       "3099  2025-04-29T16:24:54.669936  \n",
       "3100  2025-04-29T16:25:09.396585  \n",
       "\n",
       "[3101 rows x 15 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# è®€å–è³‡æ–™ï¼ˆè«‹ç¢ºèªä½ çš„ Excel è·¯å¾‘ï¼‰\n",
    "# df = pd.read_excel(base_path+\"/threads.xlsx\")\n",
    "df = pd.read_excel(\"threads.xlsx\", engine='openpyxl')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "kIM9eoPtiDSC"
   },
   "outputs": [],
   "source": [
    "# === èªè¨€åµæ¸¬ä¿®æ­£ç‰ˆ===\n",
    "lingua_detector = LanguageDetectorBuilder.from_all_languages().with_preloaded_language_models().build()\n",
    "lingua_available = True\n",
    "def detect_lang_with_preprocessing_lingua(text):\n",
    "    original_text = text\n",
    "\n",
    "    # è‹¥æ˜¯ NaN æˆ–ç©ºå­—ä¸²å°±å›å‚³ \"unknown\"\n",
    "    if pd.isna(text):\n",
    "        return \"unknown\"\n",
    "    text = str(text).strip()\n",
    "    if not text:\n",
    "        return \"unknown\"\n",
    "    \n",
    "    # ç§»é™¤ URLã€@æ¨™è¨˜ã€ #hashtagã€emojiã€å¤šé¤˜ç©ºç™½\n",
    "    try:\n",
    "      text_cleaned = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "      text_cleaned = re.sub(r'@\\w+', '', text_cleaned)\n",
    "      text_cleaned = re.sub(r'#\\w+', '', text_cleaned)\n",
    "      text_cleaned = emoji.replace_emoji(text_cleaned, replace='')\n",
    "      text_cleaned = re.sub(r'\\s+', ' ', text_cleaned).strip()\n",
    "    except Exception as e:\n",
    "      return \"error_state_preprocessing\"\n",
    "\n",
    "    # è‹¥é€™äº›æ¸…ç†å®Œå¾Œè®Šæˆç©ºå­—ä¸²\n",
    "    if not text_cleaned:\n",
    "      return \"empty_after_clean\"\n",
    "\n",
    "    # è‹¥æ–‡å­—ä¸­è¶…é 30% æ˜¯ä¸­æ–‡ï¼Œå°±ç›´æ¥åˆ¤å®šç‚º \"Ch\"ï¼ˆä¸­æ–‡ï¼‰\n",
    "    try:\n",
    "      chinese_chars = re.findall(r'[\\u4e00-\\u9fff]', text_cleaned)\n",
    "      text_len = len(text_cleaned)\n",
    "      ratio = len(chinese_chars) / max(text_len, 1)\n",
    "      chinese_threshold = 0.3\n",
    "      if ratio > chinese_threshold:\n",
    "        return \"Ch\"\n",
    "\n",
    "      # å‘¼å« lingua åµæ¸¬èªè¨€\n",
    "      detected_language = lingua_detector.detect_language_of(text_cleaned)\n",
    "\n",
    "      # è‹¥ lingua åˆ¤å®šæ˜¯ä¸­æ–‡ï¼ˆ'ZH'ï¼‰ï¼Œå‰‡å›å‚³ \"Ch\"ï¼Œå…¶é¤˜èªè¨€ä»¥å°å¯«çš„ ISO 639-1 å›å‚³ï¼ˆå¦‚ en, ja, frï¼‰\n",
    "      # è‹¥ç„¡æ³•åµæ¸¬å‡ºèªè¨€ï¼Œå›å‚³ \"unknown\"\n",
    "      if detected_language is not None:\n",
    "        iso_code = detected_language.iso_code_639_1.name\n",
    "        if iso_code == 'ZH':\n",
    "          return \"Ch\"\n",
    "        else:\n",
    "          return iso_code.lower()\n",
    "      else:\n",
    "        return \"unknown\"\n",
    "\n",
    "    except Exception as e:\n",
    "      return \"unknown\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_nqIl5HD2ia"
   },
   "source": [
    "## æ¸…æ´—æ•¸æ“šV1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "LsfgBIPFrsc1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è™•ç†å®Œæˆï¼Œå·²è¼¸å‡º threads_cleaned_v1.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>post_time</th>\n",
       "      <th>topic</th>\n",
       "      <th>time_info</th>\n",
       "      <th>content</th>\n",
       "      <th>has_photo</th>\n",
       "      <th>has_video</th>\n",
       "      <th>like_count</th>\n",
       "      <th>reply_count</th>\n",
       "      <th>repost_count</th>\n",
       "      <th>...</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>lang</th>\n",
       "      <th>scrape_time_origin</th>\n",
       "      <th>post_weekday</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>viral</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_exclaim</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>2025-04-29T10:58:39.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3å°æ™‚</td>\n",
       "      <td>Thank you God for another day.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>190</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:27</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2025-04-30 06:27:40.176749+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-04-29T12:33:44.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1å°æ™‚</td>\n",
       "      <td>ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>196</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:27</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025-04-30 06:27:54.964788+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ribboworld2021</td>\n",
       "      <td>2025-04-29T04:39:46.000Z</td>\n",
       "      <td>å°ä¸€æ—¥å¸¸</td>\n",
       "      <td>9å°æ™‚</td>\n",
       "      <td>è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>75</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025-04-30 06:28:09.873641+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>2025-04-29T11:25:22.000Z</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3å°æ™‚</td>\n",
       "      <td>Just be strong. Confident. Hopeful. Intellectu...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>83</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2025-04-30 06:28:24.726576+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jose_ykc</td>\n",
       "      <td>2025-04-29T10:36:19.000Z</td>\n",
       "      <td>è¼”ä»å¤§å­¸</td>\n",
       "      <td>3å°æ™‚</td>\n",
       "      <td>æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>4334</td>\n",
       "      <td>55</td>\n",
       "      <td>513</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025-04-30 06:28:39.393706+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>leighton.williams</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 07:30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8å°æ™‚</td>\n",
       "      <td>First tasting in California</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:23</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2025-04-30 00:23:40.328046+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>cape__man</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9å°æ™‚</td>\n",
       "      <td>I hoped it would have been better.</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:23</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2025-04-30 00:23:55.063517+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>simimoonlight</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9å°æ™‚</td>\n",
       "      <td>I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2656</td>\n",
       "      <td>29</td>\n",
       "      <td>280</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:24</td>\n",
       "      <td>ğŸ«¶ğŸ¿ğŸ¥¹</td>\n",
       "      <td>3</td>\n",
       "      <td>en</td>\n",
       "      <td>2025-04-30 00:24:39.870994+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>other98</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 12:31</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3å°æ™‚</td>\n",
       "      <td>Tonight, Canada just proved that they have a h...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>10000</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:24</td>\n",
       "      <td>ğŸ™Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>en</td>\n",
       "      <td>2025-04-30 00:24:54.669936+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>scottiebeam</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 01:33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14å°æ™‚</td>\n",
       "      <td>Yall be fighting on here â€¦ i thought threads w...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>427</td>\n",
       "      <td>76</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:25</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>2025-04-30 00:25:09.396585+08:00</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3101 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                 post_time topic time_info  \\\n",
       "0                ayofvr  2025-04-29T10:58:39.000Z   NaN       3å°æ™‚   \n",
       "1                   NaN  2025-04-29T12:33:44.000Z   NaN       1å°æ™‚   \n",
       "2        ribboworld2021  2025-04-29T04:39:46.000Z  å°ä¸€æ—¥å¸¸       9å°æ™‚   \n",
       "3                ayofvr  2025-04-29T11:25:22.000Z   NaN       3å°æ™‚   \n",
       "4              jose_ykc  2025-04-29T10:36:19.000Z  è¼”ä»å¤§å­¸       3å°æ™‚   \n",
       "...                 ...                       ...   ...       ...   \n",
       "3096  leighton.williams         2025å¹´04æœˆ29æ—¥ 07:30   NaN       8å°æ™‚   \n",
       "3097          cape__man         2025å¹´04æœˆ29æ—¥ 06:31   NaN       9å°æ™‚   \n",
       "3098      simimoonlight         2025å¹´04æœˆ29æ—¥ 06:26   NaN       9å°æ™‚   \n",
       "3099            other98         2025å¹´04æœˆ29æ—¥ 12:31   NaN       3å°æ™‚   \n",
       "3100        scottiebeam         2025å¹´04æœˆ29æ—¥ 01:33   NaN      14å°æ™‚   \n",
       "\n",
       "                                                content  has_photo  has_video  \\\n",
       "0                        Thank you God for another day.      False      False   \n",
       "1                                      ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼       True      False   \n",
       "2              è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€      False      False   \n",
       "3     Just be strong. Confident. Hopeful. Intellectu...      False      False   \n",
       "4                             æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€       True       True   \n",
       "...                                                 ...        ...        ...   \n",
       "3096                        First tasting in California      False      False   \n",
       "3097                 I hoped it would have been better.      False      False   \n",
       "3098  I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...      False      False   \n",
       "3099  Tonight, Canada just proved that they have a h...      False      False   \n",
       "3100  Yall be fighting on here â€¦ i thought threads w...      False      False   \n",
       "\n",
       "      like_count  reply_count  repost_count  ...        scrape_time  emojis  \\\n",
       "0            190            3            23  ...  2025å¹´04æœˆ30æ—¥ 06:27           \n",
       "1            196           16             0  ...  2025å¹´04æœˆ30æ—¥ 06:27           \n",
       "2             75            6             0  ...  2025å¹´04æœˆ30æ—¥ 06:28           \n",
       "3             83            5             3  ...  2025å¹´04æœˆ30æ—¥ 06:28           \n",
       "4           4334           55           513  ...  2025å¹´04æœˆ30æ—¥ 06:28           \n",
       "...          ...          ...           ...  ...                ...     ...   \n",
       "3096           7            0             0  ...  2025å¹´04æœˆ30æ—¥ 00:23           \n",
       "3097           2            0             0  ...  2025å¹´04æœˆ30æ—¥ 00:23           \n",
       "3098        2656           29           280  ...  2025å¹´04æœˆ30æ—¥ 00:24     ğŸ«¶ğŸ¿ğŸ¥¹   \n",
       "3099       10000          214           214  ...  2025å¹´04æœˆ30æ—¥ 00:24       ğŸ™Œ   \n",
       "3100         427           76            28  ...  2025å¹´04æœˆ30æ—¥ 00:25           \n",
       "\n",
       "      emoji_count lang               scrape_time_origin post_weekday  \\\n",
       "0               0   en 2025-04-30 06:27:40.176749+08:00    Wednesday   \n",
       "1               0   Ch 2025-04-30 06:27:54.964788+08:00    Wednesday   \n",
       "2               0   Ch 2025-04-30 06:28:09.873641+08:00    Wednesday   \n",
       "3               0   en 2025-04-30 06:28:24.726576+08:00    Wednesday   \n",
       "4               0   Ch 2025-04-30 06:28:39.393706+08:00    Wednesday   \n",
       "...           ...  ...                              ...          ...   \n",
       "3096            0   en 2025-04-30 00:23:40.328046+08:00    Wednesday   \n",
       "3097            0   en 2025-04-30 00:23:55.063517+08:00    Wednesday   \n",
       "3098            3   en 2025-04-30 00:24:39.870994+08:00    Wednesday   \n",
       "3099            1   en 2025-04-30 00:24:54.669936+08:00    Wednesday   \n",
       "3100            0   en 2025-04-30 00:25:09.396585+08:00    Wednesday   \n",
       "\n",
       "      post_hour viral has_question has_exclaim  \n",
       "0             6     0        False       False  \n",
       "1             6     1         True        True  \n",
       "2             6     0        False        True  \n",
       "3             6     0        False       False  \n",
       "4             6     1        False       False  \n",
       "...         ...   ...          ...         ...  \n",
       "3096          0     0        False       False  \n",
       "3097          0     0        False       False  \n",
       "3098          0     1        False       False  \n",
       "3099          0     1        False        True  \n",
       "3100          0     1        False       False  \n",
       "\n",
       "[3101 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === æ•¸å€¼æ¬„ä½æ¸…æ´—ï¼ˆè¬å­—ã€é€—è™Ÿæ ¼å¼è™•ç†ï¼‰===\n",
    "def parse_count(value):\n",
    "    # å°‡æ–‡å­—æ•¸å­—ï¼ˆå¦‚ \"1,234\"ã€\"2.5è¬\"ï¼‰çµ±ä¸€è½‰ç‚ºæ•´æ•¸ï¼ˆintï¼‰\n",
    "    if pd.isna(value): return 0\n",
    "    value = str(value).replace(\",\", \"\")\n",
    "    # \"è¬\" çš„éƒ¨åˆ†æœƒä¹˜ä¸Š 10,000 åšè½‰æ›\n",
    "    # ç„¡æ³•è™•ç†çš„æ ¼å¼å°±å›å‚³ 0\n",
    "    if \"è¬\" in value:\n",
    "        return int(float(value.replace(\"è¬\", \"\")) * 10000)\n",
    "    try:\n",
    "        return int(float(value))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "for col in [\"like_count\", \"view_count\", \"share_count\", \"repost_count\", \"reply_count\"]:\n",
    "    df[col] = df[col].apply(parse_count)\n",
    "\n",
    "# === å¸ƒæ—æ¬„ä½è™•ç† ===\n",
    "# å°‡åŸå§‹æ¬„ä½ï¼ˆY/Nï¼‰è½‰æ›ç‚º True/False\n",
    "# è™•ç†éç¨‹æœƒå»é™¤ç©ºç™½ã€è½‰æˆå¤§å¯«\n",
    "df[\"has_photo\"] = df[\"has_photo\"].apply(lambda x: str(x).strip().upper() == \"Y\")\n",
    "df[\"has_video\"] = df[\"has_video\"].apply(lambda x: str(x).strip().upper() == \"Y\")\n",
    "\n",
    "# === emoji èƒå–èˆ‡çµ±è¨ˆ ===\n",
    "# æª¢æŸ¥æ˜¯å¦ç‚ºæ–‡å­—å‹åˆ¥ï¼Œå¦‚æœæ˜¯æ–‡å­—ï¼Œå¾ä¸­èƒå–å‡ºæ‰€æœ‰ emoji å­—å…ƒä¸¦ä¸²æ¥æˆå­—ä¸²å›å‚³\n",
    "def extract_emojis(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    return \"\".join([ch for ch in text if ch in emoji.EMOJI_DATA])\n",
    "\n",
    "df[\"emojis\"] = df[\"content\"].apply(extract_emojis)\n",
    "df[\"emoji_count\"] = df[\"emojis\"].apply(len)\n",
    "\n",
    "# # === èªè¨€åµæ¸¬ä¿®æ­£ç‰ˆ===\n",
    "# def detect_lang_custom(text):\n",
    "#     try:\n",
    "#         text = str(text)\n",
    "#         chinese_chars = re.findall(r'[\\u4e00-\\u9fff]', text)\n",
    "#         if len(chinese_chars) / max(len(text), 1) > 0.3:\n",
    "#             return \"Ch\"\n",
    "#         return detect(text)\n",
    "#     except:\n",
    "#         return \"unknown\"\n",
    "\n",
    "# ä½¿ç”¨å…ˆå‰å®šç¾©å¥½çš„èªè¨€åµæ¸¬å‡½æ•¸ detect_lang_with_preprocessing_lingua()ï¼Œè™•ç†æ¯ç¯‡æ–‡ç« çš„èªè¨€åˆ¤å®š\n",
    "df[\"lang\"] = df[\"content\"].apply(detect_lang_with_preprocessing_lingua)\n",
    "\n",
    "# === scrape_time è™•ç†ï¼ˆè½‰æ›æ™‚å€ + æŠ½å–æ˜ŸæœŸèˆ‡å°æ™‚ï¼‰===\n",
    "# å°‡æ™‚é–“æ¬„ä½è½‰ç‚ºå°åŒ—æ™‚å€ï¼Œé¡å¤–æŠ½å‡ºæ ¼å¼åŒ–å¾Œçš„æ™‚é–“å­—ä¸²ã€æ˜ŸæœŸå¹¾ã€å°æ™‚(0â€“23ï¼‰\n",
    "df[\"scrape_time_origin\"] = pd.to_datetime(df[\"scrape_time\"], utc=True).dt.tz_convert(\"Asia/Taipei\")\n",
    "df[\"scrape_time\"]  = df[\"scrape_time_origin\"].dt.strftime(\"%Yå¹´%mæœˆ%dæ—¥ %H:%M\")\n",
    "df[\"post_weekday\"] = df[\"scrape_time_origin\"].dt.day_name()\n",
    "df[\"post_hour\"] = df[\"scrape_time_origin\"].dt.hour\n",
    "\n",
    "# === æ˜¯å¦ç‚ºé«˜æµé‡æ–‡ç« ï¼ˆç ´è¬ï¼‰===\n",
    "# è¶…éç­‰æ–¼ 10,000 ç€è¦½ç‚º 1ï¼Œå…¶é¤˜ç‚º 0\n",
    "df[\"viral\"] = (df[\"view_count\"] >= 10000).astype(int)\n",
    "\n",
    "# === æ˜¯å¦ä½¿ç”¨å•è™Ÿã€é©šå˜†è™Ÿ ===\n",
    "df[\"has_question\"] = df[\"content\"].apply(lambda x: \"ï¼Ÿ\" in str(x) or \"?\" in str(x))\n",
    "df[\"has_exclaim\"] = df[\"content\"].apply(lambda x: \"ï¼\" in str(x) or \"!\" in str(x))\n",
    "\n",
    "# === å„²å­˜çµæœ ===\n",
    "df.to_csv(\"threads_cleaned_v1.csv\",encoding='utf_8_sig', index=False)\n",
    "print(\"âœ… è™•ç†å®Œæˆï¼Œå·²è¼¸å‡º threads_cleaned_v1.csv\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KTVtegcwEfb1"
   },
   "source": [
    "## æ¸…æ´—æ•¸æ“šV2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_a9vHZ0p9o2u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… è™•ç†å®Œæˆï¼Œå·²è¼¸å‡º threads_cleaned_v2.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>content_length</th>\n",
       "      <th>lang</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>post_weekday</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_period</th>\n",
       "      <th>viral</th>\n",
       "      <th>post_time</th>\n",
       "      <th>...</th>\n",
       "      <th>followers_count</th>\n",
       "      <th>post_url</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>scrape_time_origin</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_exclaim</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_mention</th>\n",
       "      <th>has_hashtag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>Thank you God for another day.</td>\n",
       "      <td>30</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:27</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T10:58:39.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>141073</td>\n",
       "      <td>https://www.threads.net/@ayofvr/post/DJBymf8uTrK</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:27:40.176749+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼</td>\n",
       "      <td>16</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:27</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-29T12:33:44.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>77683</td>\n",
       "      <td>https://www.threads.net/@ban.mei.onnnnni/post/...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:27:54.964788+08:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ribboworld2021</td>\n",
       "      <td>è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€</td>\n",
       "      <td>40</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T04:39:46.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>99</td>\n",
       "      <td>https://www.threads.net/@ribboworld2021/post/D...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:09.873641+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>Just be strong. Confident. Hopeful. Intellectu...</td>\n",
       "      <td>69</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T11:25:22.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>141093</td>\n",
       "      <td>https://www.threads.net/@ayofvr/post/DJB1qP5OmzP</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:24.726576+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jose_ykc</td>\n",
       "      <td>æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€</td>\n",
       "      <td>25</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-29T10:36:19.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>https://www.threads.net/@jose_ykc/post/DJBvpGI...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:39.393706+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>leighton.williams</td>\n",
       "      <td>First tasting in California</td>\n",
       "      <td>27</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:23</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 07:30</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>https://www.threads.net/@leighton.williams/pos...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:23:40.328046+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>cape__man</td>\n",
       "      <td>I hoped it would have been better.</td>\n",
       "      <td>34</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:23</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:31</td>\n",
       "      <td>...</td>\n",
       "      <td>114</td>\n",
       "      <td>https://www.threads.net/@cape__man/post/DJAdFd...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:23:55.063517+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>simimoonlight</td>\n",
       "      <td>I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...</td>\n",
       "      <td>51</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:26</td>\n",
       "      <td>...</td>\n",
       "      <td>65732</td>\n",
       "      <td>https://www.threads.net/@simimoonlight/post/DJ...</td>\n",
       "      <td>ğŸ«¶ğŸ¿ğŸ¥¹</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-30 00:24:39.870994+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>other98</td>\n",
       "      <td>Tonight, Canada just proved that they have a h...</td>\n",
       "      <td>77</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 12:31</td>\n",
       "      <td>...</td>\n",
       "      <td>217182</td>\n",
       "      <td>https://www.threads.net/@other98/post/DJBGV3NxiX_</td>\n",
       "      <td>ğŸ™Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 00:24:54.669936+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>scottiebeam</td>\n",
       "      <td>Yall be fighting on here â€¦ i thought threads w...</td>\n",
       "      <td>57</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:25</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 01:33</td>\n",
       "      <td>...</td>\n",
       "      <td>59249</td>\n",
       "      <td>https://www.threads.net/@scottiebeam/post/DI_6...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:25:09.396585+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3101 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                            content  \\\n",
       "0                ayofvr                     Thank you God for another day.   \n",
       "1                   NaN                                   ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼   \n",
       "2        ribboworld2021           è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€   \n",
       "3                ayofvr  Just be strong. Confident. Hopeful. Intellectu...   \n",
       "4              jose_ykc                          æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€   \n",
       "...                 ...                                                ...   \n",
       "3096  leighton.williams                        First tasting in California   \n",
       "3097          cape__man                 I hoped it would have been better.   \n",
       "3098      simimoonlight  I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...   \n",
       "3099            other98  Tonight, Canada just proved that they have a h...   \n",
       "3100        scottiebeam  Yall be fighting on here â€¦ i thought threads w...   \n",
       "\n",
       "      content_length lang        scrape_time post_weekday  post_hour  \\\n",
       "0                 30   en  2025å¹´04æœˆ30æ—¥ 06:27    Wednesday          6   \n",
       "1                 16   Ch  2025å¹´04æœˆ30æ—¥ 06:27    Wednesday          6   \n",
       "2                 40   Ch  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "3                 69   en  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "4                 25   Ch  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "...              ...  ...                ...          ...        ...   \n",
       "3096              27   en  2025å¹´04æœˆ30æ—¥ 00:23    Wednesday          0   \n",
       "3097              34   en  2025å¹´04æœˆ30æ—¥ 00:23    Wednesday          0   \n",
       "3098              51   en  2025å¹´04æœˆ30æ—¥ 00:24    Wednesday          0   \n",
       "3099              77   en  2025å¹´04æœˆ30æ—¥ 00:24    Wednesday          0   \n",
       "3100              57   en  2025å¹´04æœˆ30æ—¥ 00:25    Wednesday          0   \n",
       "\n",
       "     post_period  viral                 post_time  ... followers_count  \\\n",
       "0        morning      0  2025-04-29T10:58:39.000Z  ...          141073   \n",
       "1        morning      1  2025-04-29T12:33:44.000Z  ...           77683   \n",
       "2        morning      0  2025-04-29T04:39:46.000Z  ...              99   \n",
       "3        morning      0  2025-04-29T11:25:22.000Z  ...          141093   \n",
       "4        morning      1  2025-04-29T10:36:19.000Z  ...              65   \n",
       "...          ...    ...                       ...  ...             ...   \n",
       "3096       night      0         2025å¹´04æœˆ29æ—¥ 07:30  ...              30   \n",
       "3097       night      0         2025å¹´04æœˆ29æ—¥ 06:31  ...             114   \n",
       "3098       night      1         2025å¹´04æœˆ29æ—¥ 06:26  ...           65732   \n",
       "3099       night      1         2025å¹´04æœˆ29æ—¥ 12:31  ...          217182   \n",
       "3100       night      1         2025å¹´04æœˆ29æ—¥ 01:33  ...           59249   \n",
       "\n",
       "                                               post_url  emojis  emoji_count  \\\n",
       "0      https://www.threads.net/@ayofvr/post/DJBymf8uTrK                    0   \n",
       "1     https://www.threads.net/@ban.mei.onnnnni/post/...                    0   \n",
       "2     https://www.threads.net/@ribboworld2021/post/D...                    0   \n",
       "3      https://www.threads.net/@ayofvr/post/DJB1qP5OmzP                    0   \n",
       "4     https://www.threads.net/@jose_ykc/post/DJBvpGI...                    0   \n",
       "...                                                 ...     ...          ...   \n",
       "3096  https://www.threads.net/@leighton.williams/pos...                    0   \n",
       "3097  https://www.threads.net/@cape__man/post/DJAdFd...                    0   \n",
       "3098  https://www.threads.net/@simimoonlight/post/DJ...     ğŸ«¶ğŸ¿ğŸ¥¹            3   \n",
       "3099  https://www.threads.net/@other98/post/DJBGV3NxiX_       ğŸ™Œ            1   \n",
       "3100  https://www.threads.net/@scottiebeam/post/DI_6...                    0   \n",
       "\n",
       "                   scrape_time_origin  has_question  has_exclaim  has_url  \\\n",
       "0    2025-04-30 06:27:40.176749+08:00         False        False    False   \n",
       "1    2025-04-30 06:27:54.964788+08:00          True         True    False   \n",
       "2    2025-04-30 06:28:09.873641+08:00         False         True    False   \n",
       "3    2025-04-30 06:28:24.726576+08:00         False        False    False   \n",
       "4    2025-04-30 06:28:39.393706+08:00         False        False    False   \n",
       "...                               ...           ...          ...      ...   \n",
       "3096 2025-04-30 00:23:40.328046+08:00         False        False    False   \n",
       "3097 2025-04-30 00:23:55.063517+08:00         False        False    False   \n",
       "3098 2025-04-30 00:24:39.870994+08:00         False        False    False   \n",
       "3099 2025-04-30 00:24:54.669936+08:00         False         True    False   \n",
       "3100 2025-04-30 00:25:09.396585+08:00         False        False    False   \n",
       "\n",
       "      has_mention  has_hashtag  \n",
       "0           False        False  \n",
       "1           False        False  \n",
       "2           False        False  \n",
       "3           False        False  \n",
       "4           False        False  \n",
       "...           ...          ...  \n",
       "3096        False        False  \n",
       "3097        False        False  \n",
       "3098        False        False  \n",
       "3099        False        False  \n",
       "3100        False        False  \n",
       "\n",
       "[3101 rows x 29 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# --- æ–‡ç« é•·åº¦ ---\n",
    "df[\"content_length\"] = df[\"content\"].apply(lambda x: len(str(x)))\n",
    "\n",
    "# --- æ˜¯å¦åŒ…å«ç¶²å€ ---\n",
    "df[\"has_url\"] = df[\"content\"].apply(lambda x: \"http\" in str(x) or \"www.\" in str(x))\n",
    "\n",
    "# --- æ˜¯å¦åŒ…å« @æ¨™è¨˜ä»–äºº ---\n",
    "df[\"has_mention\"] = df[\"content\"].apply(lambda x: \"@\" in str(x))\n",
    "\n",
    "# --- æ˜¯å¦ä½¿ç”¨ Hashtag ---\n",
    "df[\"has_hashtag\"] = df[\"content\"].apply(lambda x: \"#\" in str(x))\n",
    "\n",
    "# è²¼æ–‡ä¸»é¡Œå­—è©æå–ï¼ˆå¯å¾ŒçºŒåš TF-IDF æˆ–ä¸»é¡Œå»ºæ¨¡ï¼‰\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "vectorizer = CountVectorizer(max_features=100, stop_words='english')\n",
    "word_matrix = vectorizer.fit_transform(df['content'].astype(str))\n",
    "\n",
    "# å°‡å¸¸è¦‹è©èªæå–å‡ºä¾†\n",
    "keywords = vectorizer.get_feature_names_out()\n",
    "\n",
    "# æ˜¯å¦ç‚ºæ·±å¤œæˆ–ç™½å¤©è²¼æ–‡ï¼ˆæ™‚é–“æ®µåˆ†é¡ï¼‰\n",
    "def time_period(hour):\n",
    "    if 5 <= hour < 12:\n",
    "        return \"morning\"\n",
    "    elif 12 <= hour < 17:\n",
    "        return \"afternoon\"\n",
    "    elif 17 <= hour < 22:\n",
    "        return \"evening\"\n",
    "    else:\n",
    "        return \"night\"\n",
    "\n",
    "df[\"post_period\"] = df[\"post_hour\"].apply(time_period)\n",
    "\n",
    "cols_to_show_first = ['author', 'content', 'content_length', 'lang', 'scrape_time', 'post_weekday', 'post_hour', 'post_period', 'viral']\n",
    "df = df[cols_to_show_first + [col for col in df.columns if col not in cols_to_show_first]]\n",
    "df.to_csv(\"threads_cleaned_v2.csv\",encoding='utf_8_sig',index=False)\n",
    "print(\"âœ… è™•ç†å®Œæˆï¼Œå·²è¼¸å‡º threads_cleaned_v2.csv\")\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention æ¨¡çµ„è™•ç†æ–‡å­—è³‡æ–™ï¼ˆæ¸¬è©¦ä¸­ å› æœªå¯«å®Œå¯å…ˆè·³éï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/59/tx1m33l955b0h85n6dlwm4440000gn/T/ipykernel_1391/3744166298.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"semantic_text\"] = df.apply(build_semantic_text, axis=1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>content_length</th>\n",
       "      <th>lang</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>post_weekday</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_period</th>\n",
       "      <th>viral</th>\n",
       "      <th>post_time</th>\n",
       "      <th>...</th>\n",
       "      <th>post_url</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>scrape_time_origin</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_exclaim</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_mention</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>semantic_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>Thank you God for another day.</td>\n",
       "      <td>30</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:27</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T10:58:39.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@ayofvr/post/DJBymf8uTrK</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:27:40.176749+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: ayofvr emojis:  content: Thank you ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼</td>\n",
       "      <td>16</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:27</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-29T12:33:44.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@ban.mei.onnnnni/post/...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:27:54.964788+08:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>emojis:  content: ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ribboworld2021</td>\n",
       "      <td>è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€</td>\n",
       "      <td>40</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T04:39:46.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@ribboworld2021/post/D...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:09.873641+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: ribboworld2021 topic: å°ä¸€æ—¥å¸¸ emojis: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>Just be strong. Confident. Hopeful. Intellectu...</td>\n",
       "      <td>69</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T11:25:22.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@ayofvr/post/DJB1qP5OmzP</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:24.726576+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: ayofvr emojis:  content: Just be st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jose_ykc</td>\n",
       "      <td>æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€</td>\n",
       "      <td>25</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-29T10:36:19.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@jose_ykc/post/DJBvpGI...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:39.393706+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: jose_ykc topic: è¼”ä»å¤§å­¸ emojis:  conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>leighton.williams</td>\n",
       "      <td>First tasting in California</td>\n",
       "      <td>27</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:23</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 07:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@leighton.williams/pos...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:23:40.328046+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: leighton.williams emojis:  content:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>cape__man</td>\n",
       "      <td>I hoped it would have been better.</td>\n",
       "      <td>34</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:23</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:31</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@cape__man/post/DJAdFd...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:23:55.063517+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: cape__man emojis:  content: I hoped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>simimoonlight</td>\n",
       "      <td>I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...</td>\n",
       "      <td>51</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:26</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@simimoonlight/post/DJ...</td>\n",
       "      <td>ğŸ«¶ğŸ¿ğŸ¥¹</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-30 00:24:39.870994+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: simimoonlight emojis: ğŸ«¶ ğŸ¿ ğŸ¥¹ content...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>other98</td>\n",
       "      <td>Tonight, Canada just proved that they have a h...</td>\n",
       "      <td>77</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 12:31</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@other98/post/DJBGV3NxiX_</td>\n",
       "      <td>ğŸ™Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 00:24:54.669936+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: other98 emojis: ğŸ™Œ content: Tonight,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>scottiebeam</td>\n",
       "      <td>Yall be fighting on here â€¦ i thought threads w...</td>\n",
       "      <td>57</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:25</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 01:33</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@scottiebeam/post/DI_6...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:25:09.396585+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>author_id: scottiebeam emojis:  content: Yall ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3101 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                            content  \\\n",
       "0                ayofvr                     Thank you God for another day.   \n",
       "1                   NaN                                   ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼   \n",
       "2        ribboworld2021           è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€   \n",
       "3                ayofvr  Just be strong. Confident. Hopeful. Intellectu...   \n",
       "4              jose_ykc                          æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€   \n",
       "...                 ...                                                ...   \n",
       "3096  leighton.williams                        First tasting in California   \n",
       "3097          cape__man                 I hoped it would have been better.   \n",
       "3098      simimoonlight  I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...   \n",
       "3099            other98  Tonight, Canada just proved that they have a h...   \n",
       "3100        scottiebeam  Yall be fighting on here â€¦ i thought threads w...   \n",
       "\n",
       "      content_length lang        scrape_time post_weekday  post_hour  \\\n",
       "0                 30   en  2025å¹´04æœˆ30æ—¥ 06:27    Wednesday          6   \n",
       "1                 16   Ch  2025å¹´04æœˆ30æ—¥ 06:27    Wednesday          6   \n",
       "2                 40   Ch  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "3                 69   en  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "4                 25   Ch  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "...              ...  ...                ...          ...        ...   \n",
       "3096              27   en  2025å¹´04æœˆ30æ—¥ 00:23    Wednesday          0   \n",
       "3097              34   en  2025å¹´04æœˆ30æ—¥ 00:23    Wednesday          0   \n",
       "3098              51   en  2025å¹´04æœˆ30æ—¥ 00:24    Wednesday          0   \n",
       "3099              77   en  2025å¹´04æœˆ30æ—¥ 00:24    Wednesday          0   \n",
       "3100              57   en  2025å¹´04æœˆ30æ—¥ 00:25    Wednesday          0   \n",
       "\n",
       "     post_period  viral                 post_time  ...  \\\n",
       "0        morning      0  2025-04-29T10:58:39.000Z  ...   \n",
       "1        morning      1  2025-04-29T12:33:44.000Z  ...   \n",
       "2        morning      0  2025-04-29T04:39:46.000Z  ...   \n",
       "3        morning      0  2025-04-29T11:25:22.000Z  ...   \n",
       "4        morning      1  2025-04-29T10:36:19.000Z  ...   \n",
       "...          ...    ...                       ...  ...   \n",
       "3096       night      0         2025å¹´04æœˆ29æ—¥ 07:30  ...   \n",
       "3097       night      0         2025å¹´04æœˆ29æ—¥ 06:31  ...   \n",
       "3098       night      1         2025å¹´04æœˆ29æ—¥ 06:26  ...   \n",
       "3099       night      1         2025å¹´04æœˆ29æ—¥ 12:31  ...   \n",
       "3100       night      1         2025å¹´04æœˆ29æ—¥ 01:33  ...   \n",
       "\n",
       "                                               post_url emojis  emoji_count  \\\n",
       "0      https://www.threads.net/@ayofvr/post/DJBymf8uTrK                   0   \n",
       "1     https://www.threads.net/@ban.mei.onnnnni/post/...                   0   \n",
       "2     https://www.threads.net/@ribboworld2021/post/D...                   0   \n",
       "3      https://www.threads.net/@ayofvr/post/DJB1qP5OmzP                   0   \n",
       "4     https://www.threads.net/@jose_ykc/post/DJBvpGI...                   0   \n",
       "...                                                 ...    ...          ...   \n",
       "3096  https://www.threads.net/@leighton.williams/pos...                   0   \n",
       "3097  https://www.threads.net/@cape__man/post/DJAdFd...                   0   \n",
       "3098  https://www.threads.net/@simimoonlight/post/DJ...    ğŸ«¶ğŸ¿ğŸ¥¹            3   \n",
       "3099  https://www.threads.net/@other98/post/DJBGV3NxiX_      ğŸ™Œ            1   \n",
       "3100  https://www.threads.net/@scottiebeam/post/DI_6...                   0   \n",
       "\n",
       "                   scrape_time_origin  has_question  has_exclaim  has_url  \\\n",
       "0    2025-04-30 06:27:40.176749+08:00         False        False    False   \n",
       "1    2025-04-30 06:27:54.964788+08:00          True         True    False   \n",
       "2    2025-04-30 06:28:09.873641+08:00         False         True    False   \n",
       "3    2025-04-30 06:28:24.726576+08:00         False        False    False   \n",
       "4    2025-04-30 06:28:39.393706+08:00         False        False    False   \n",
       "...                               ...           ...          ...      ...   \n",
       "3096 2025-04-30 00:23:40.328046+08:00         False        False    False   \n",
       "3097 2025-04-30 00:23:55.063517+08:00         False        False    False   \n",
       "3098 2025-04-30 00:24:39.870994+08:00         False        False    False   \n",
       "3099 2025-04-30 00:24:54.669936+08:00         False         True    False   \n",
       "3100 2025-04-30 00:25:09.396585+08:00         False        False    False   \n",
       "\n",
       "      has_mention  has_hashtag  \\\n",
       "0           False        False   \n",
       "1           False        False   \n",
       "2           False        False   \n",
       "3           False        False   \n",
       "4           False        False   \n",
       "...           ...          ...   \n",
       "3096        False        False   \n",
       "3097        False        False   \n",
       "3098        False        False   \n",
       "3099        False        False   \n",
       "3100        False        False   \n",
       "\n",
       "                                          semantic_text  \n",
       "0     author_id: ayofvr emojis:  content: Thank you ...  \n",
       "1                    emojis:  content: ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼  \n",
       "2     author_id: ribboworld2021 topic: å°ä¸€æ—¥å¸¸ emojis: ...  \n",
       "3     author_id: ayofvr emojis:  content: Just be st...  \n",
       "4     author_id: jose_ykc topic: è¼”ä»å¤§å­¸ emojis:  conte...  \n",
       "...                                                 ...  \n",
       "3096  author_id: leighton.williams emojis:  content:...  \n",
       "3097  author_id: cape__man emojis:  content: I hoped...  \n",
       "3098  author_id: simimoonlight emojis: ğŸ«¶ ğŸ¿ ğŸ¥¹ content...  \n",
       "3099  author_id: other98 emojis: ğŸ™Œ content: Tonight,...  \n",
       "3100  author_id: scottiebeam emojis:  content: Yall ...  \n",
       "\n",
       "[3101 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_semantic_text(row):\n",
    "    parts = []\n",
    "\n",
    "    # ä½œè€…è³‡è¨ŠåŠ ä¸Šå‰ç¶´\n",
    "    if pd.notna(row[\"author\"]):\n",
    "        parts.append(f\"author_id: {row['author']}\")\n",
    "\n",
    "    # ä¸»é¡Œåˆ†é¡åŠ ä¸Šå‰ç¶´\n",
    "    if pd.notna(row[\"topic\"]):\n",
    "        parts.append(f\"topic: {row['topic']}\")\n",
    "\n",
    "    # Emoji ç•¶ä½œæƒ…æ„Ÿç¬¦è™Ÿï¼Œåˆä½µæˆä¸€ä¸²æ–‡å­—\n",
    "    if pd.notna(row[\"emojis\"]):\n",
    "        emoji_text = \" \".join(row[\"emojis\"])\n",
    "        parts.append(f\"emojis: {emoji_text}\")\n",
    "\n",
    "    # è²¼æ–‡æ­£æ–‡\n",
    "    if pd.notna(row[\"content\"]):\n",
    "        parts.append(f\"content: {row['content']}\")\n",
    "\n",
    "    return \" \".join(parts)\n",
    "\n",
    "# æ‡‰ç”¨åˆ° DataFrame\n",
    "df[\"semantic_text\"] = df.apply(build_semantic_text, axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# 1. è¼‰å…¥ tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "\n",
    "# 2. è‡ªè¨‚ Dataset é¡åˆ¥\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, max_len=128):\n",
    "        self.encodings = tokenizer(\n",
    "            texts, \n",
    "            truncation=True, \n",
    "            padding='max_length', \n",
    "            max_length=max_len, \n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings[\"input_ids\"])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_ids\": self.encodings[\"input_ids\"][idx],\n",
    "            \"attention_mask\": self.encodings[\"attention_mask\"][idx]\n",
    "        }\n",
    "\n",
    "# 3. å»ºç«‹ dataset å’Œ dataloader\n",
    "texts = df[\"content\"].astype(str).tolist()\n",
    "text_dataset = TextDataset(texts)\n",
    "text_loader = DataLoader(text_dataset, batch_size=32)\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class SelfAttentionEncoder(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=768, num_heads=4):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
    "        self.attention = nn.MultiheadAttention(embed_dim=embed_dim, num_heads=num_heads, batch_first=True)\n",
    "        self.norm = nn.LayerNorm(embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)  # å¯é¸åŠ å¼·è½‰æ›\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        x = self.embedding(input_ids)  # [B, T, D]\n",
    "        attn_output, _ = self.attention(x, x, x, key_padding_mask=~attention_mask.bool())\n",
    "        x = self.norm(attn_output + x)\n",
    "        x = self.fc(x)\n",
    "        cls_rep = x[:, 0, :] \n",
    "        return cls_rep\n",
    "\n",
    "# åˆå§‹åŒ–æ¨¡å‹\n",
    "vocab_size = tokenizer.vocab_size\n",
    "model = SelfAttentionEncoder(vocab_size)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# æå–èªæ„å‘é‡ Z_text\n",
    "Z_text_list = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in text_loader:\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        Z_text = model(input_ids, attention_mask)  # [B, 768]\n",
    "        Z_text_list.append(Z_text.cpu())\n",
    "\n",
    "Z_text_tensor = torch.cat(Z_text_list, dim=0)  # [N, 768]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.185373</td>\n",
       "      <td>0.116477</td>\n",
       "      <td>0.122377</td>\n",
       "      <td>0.404507</td>\n",
       "      <td>-0.339129</td>\n",
       "      <td>-0.347968</td>\n",
       "      <td>-0.377152</td>\n",
       "      <td>-0.266511</td>\n",
       "      <td>0.258730</td>\n",
       "      <td>-0.805666</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437772</td>\n",
       "      <td>1.143777</td>\n",
       "      <td>-0.130535</td>\n",
       "      <td>0.552972</td>\n",
       "      <td>0.508016</td>\n",
       "      <td>-0.661004</td>\n",
       "      <td>0.648708</td>\n",
       "      <td>0.508159</td>\n",
       "      <td>0.471049</td>\n",
       "      <td>0.812747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.118061</td>\n",
       "      <td>0.158701</td>\n",
       "      <td>0.106780</td>\n",
       "      <td>0.251318</td>\n",
       "      <td>-0.336016</td>\n",
       "      <td>-0.447374</td>\n",
       "      <td>-0.266132</td>\n",
       "      <td>-0.184926</td>\n",
       "      <td>0.391666</td>\n",
       "      <td>-0.695012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.470352</td>\n",
       "      <td>1.147053</td>\n",
       "      <td>-0.160061</td>\n",
       "      <td>0.309530</td>\n",
       "      <td>0.539303</td>\n",
       "      <td>-0.772830</td>\n",
       "      <td>0.498029</td>\n",
       "      <td>0.462456</td>\n",
       "      <td>0.497207</td>\n",
       "      <td>0.803436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160336</td>\n",
       "      <td>0.090955</td>\n",
       "      <td>0.141805</td>\n",
       "      <td>0.271038</td>\n",
       "      <td>-0.268028</td>\n",
       "      <td>-0.443410</td>\n",
       "      <td>-0.325646</td>\n",
       "      <td>-0.121320</td>\n",
       "      <td>0.362589</td>\n",
       "      <td>-0.728238</td>\n",
       "      <td>...</td>\n",
       "      <td>0.423751</td>\n",
       "      <td>1.035433</td>\n",
       "      <td>-0.356109</td>\n",
       "      <td>0.497018</td>\n",
       "      <td>0.418673</td>\n",
       "      <td>-0.695262</td>\n",
       "      <td>0.535084</td>\n",
       "      <td>0.468965</td>\n",
       "      <td>0.534107</td>\n",
       "      <td>0.722016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.076843</td>\n",
       "      <td>0.105067</td>\n",
       "      <td>0.052723</td>\n",
       "      <td>0.331179</td>\n",
       "      <td>-0.202970</td>\n",
       "      <td>-0.429289</td>\n",
       "      <td>-0.354241</td>\n",
       "      <td>-0.151234</td>\n",
       "      <td>0.392680</td>\n",
       "      <td>-0.755461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.332896</td>\n",
       "      <td>1.001550</td>\n",
       "      <td>-0.155210</td>\n",
       "      <td>0.619413</td>\n",
       "      <td>0.462634</td>\n",
       "      <td>-0.595787</td>\n",
       "      <td>0.625809</td>\n",
       "      <td>0.477340</td>\n",
       "      <td>0.576133</td>\n",
       "      <td>0.758163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.138116</td>\n",
       "      <td>0.084057</td>\n",
       "      <td>0.129734</td>\n",
       "      <td>0.177018</td>\n",
       "      <td>-0.317661</td>\n",
       "      <td>-0.374959</td>\n",
       "      <td>-0.301814</td>\n",
       "      <td>-0.134798</td>\n",
       "      <td>0.365255</td>\n",
       "      <td>-0.658869</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398198</td>\n",
       "      <td>1.032260</td>\n",
       "      <td>-0.304353</td>\n",
       "      <td>0.398853</td>\n",
       "      <td>0.552792</td>\n",
       "      <td>-0.693314</td>\n",
       "      <td>0.558638</td>\n",
       "      <td>0.415872</td>\n",
       "      <td>0.535430</td>\n",
       "      <td>0.751466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>1.089460</td>\n",
       "      <td>0.230556</td>\n",
       "      <td>0.096753</td>\n",
       "      <td>0.355270</td>\n",
       "      <td>-0.262501</td>\n",
       "      <td>-0.373350</td>\n",
       "      <td>-0.388324</td>\n",
       "      <td>-0.285172</td>\n",
       "      <td>0.496985</td>\n",
       "      <td>-0.821012</td>\n",
       "      <td>...</td>\n",
       "      <td>0.436395</td>\n",
       "      <td>1.199498</td>\n",
       "      <td>-0.107245</td>\n",
       "      <td>0.401726</td>\n",
       "      <td>0.564576</td>\n",
       "      <td>-0.815372</td>\n",
       "      <td>0.613472</td>\n",
       "      <td>0.482972</td>\n",
       "      <td>0.583095</td>\n",
       "      <td>0.766825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>1.079693</td>\n",
       "      <td>0.206142</td>\n",
       "      <td>0.059271</td>\n",
       "      <td>0.246766</td>\n",
       "      <td>-0.208253</td>\n",
       "      <td>-0.328518</td>\n",
       "      <td>-0.396139</td>\n",
       "      <td>-0.210764</td>\n",
       "      <td>0.441348</td>\n",
       "      <td>-0.776673</td>\n",
       "      <td>...</td>\n",
       "      <td>0.388379</td>\n",
       "      <td>0.950016</td>\n",
       "      <td>-0.213405</td>\n",
       "      <td>0.464987</td>\n",
       "      <td>0.501455</td>\n",
       "      <td>-0.790398</td>\n",
       "      <td>0.626000</td>\n",
       "      <td>0.466310</td>\n",
       "      <td>0.540599</td>\n",
       "      <td>0.711200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>1.129379</td>\n",
       "      <td>0.108640</td>\n",
       "      <td>0.122049</td>\n",
       "      <td>0.300188</td>\n",
       "      <td>-0.298384</td>\n",
       "      <td>-0.332469</td>\n",
       "      <td>-0.461424</td>\n",
       "      <td>-0.200608</td>\n",
       "      <td>0.412536</td>\n",
       "      <td>-0.822279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.437023</td>\n",
       "      <td>1.012208</td>\n",
       "      <td>-0.170115</td>\n",
       "      <td>0.577867</td>\n",
       "      <td>0.450494</td>\n",
       "      <td>-0.554175</td>\n",
       "      <td>0.630714</td>\n",
       "      <td>0.495547</td>\n",
       "      <td>0.548192</td>\n",
       "      <td>0.719363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>1.063507</td>\n",
       "      <td>0.102142</td>\n",
       "      <td>0.152797</td>\n",
       "      <td>0.225523</td>\n",
       "      <td>-0.329202</td>\n",
       "      <td>-0.329178</td>\n",
       "      <td>-0.355302</td>\n",
       "      <td>-0.101184</td>\n",
       "      <td>0.401613</td>\n",
       "      <td>-0.827614</td>\n",
       "      <td>...</td>\n",
       "      <td>0.340202</td>\n",
       "      <td>1.069342</td>\n",
       "      <td>-0.156227</td>\n",
       "      <td>0.479461</td>\n",
       "      <td>0.446085</td>\n",
       "      <td>-0.610415</td>\n",
       "      <td>0.554650</td>\n",
       "      <td>0.437024</td>\n",
       "      <td>0.644774</td>\n",
       "      <td>0.715786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>1.107659</td>\n",
       "      <td>0.133675</td>\n",
       "      <td>0.157146</td>\n",
       "      <td>0.307179</td>\n",
       "      <td>-0.363217</td>\n",
       "      <td>-0.364786</td>\n",
       "      <td>-0.397355</td>\n",
       "      <td>-0.150967</td>\n",
       "      <td>0.458223</td>\n",
       "      <td>-0.829984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.371882</td>\n",
       "      <td>1.058214</td>\n",
       "      <td>-0.190540</td>\n",
       "      <td>0.491995</td>\n",
       "      <td>0.454371</td>\n",
       "      <td>-0.690442</td>\n",
       "      <td>0.558352</td>\n",
       "      <td>0.457464</td>\n",
       "      <td>0.483374</td>\n",
       "      <td>0.741767</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3101 rows Ã— 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6    \\\n",
       "0     1.185373  0.116477  0.122377  0.404507 -0.339129 -0.347968 -0.377152   \n",
       "1     1.118061  0.158701  0.106780  0.251318 -0.336016 -0.447374 -0.266132   \n",
       "2     1.160336  0.090955  0.141805  0.271038 -0.268028 -0.443410 -0.325646   \n",
       "3     1.076843  0.105067  0.052723  0.331179 -0.202970 -0.429289 -0.354241   \n",
       "4     1.138116  0.084057  0.129734  0.177018 -0.317661 -0.374959 -0.301814   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "3096  1.089460  0.230556  0.096753  0.355270 -0.262501 -0.373350 -0.388324   \n",
       "3097  1.079693  0.206142  0.059271  0.246766 -0.208253 -0.328518 -0.396139   \n",
       "3098  1.129379  0.108640  0.122049  0.300188 -0.298384 -0.332469 -0.461424   \n",
       "3099  1.063507  0.102142  0.152797  0.225523 -0.329202 -0.329178 -0.355302   \n",
       "3100  1.107659  0.133675  0.157146  0.307179 -0.363217 -0.364786 -0.397355   \n",
       "\n",
       "           7         8         9    ...       758       759       760  \\\n",
       "0    -0.266511  0.258730 -0.805666  ...  0.437772  1.143777 -0.130535   \n",
       "1    -0.184926  0.391666 -0.695012  ...  0.470352  1.147053 -0.160061   \n",
       "2    -0.121320  0.362589 -0.728238  ...  0.423751  1.035433 -0.356109   \n",
       "3    -0.151234  0.392680 -0.755461  ...  0.332896  1.001550 -0.155210   \n",
       "4    -0.134798  0.365255 -0.658869  ...  0.398198  1.032260 -0.304353   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "3096 -0.285172  0.496985 -0.821012  ...  0.436395  1.199498 -0.107245   \n",
       "3097 -0.210764  0.441348 -0.776673  ...  0.388379  0.950016 -0.213405   \n",
       "3098 -0.200608  0.412536 -0.822279  ...  0.437023  1.012208 -0.170115   \n",
       "3099 -0.101184  0.401613 -0.827614  ...  0.340202  1.069342 -0.156227   \n",
       "3100 -0.150967  0.458223 -0.829984  ...  0.371882  1.058214 -0.190540   \n",
       "\n",
       "           761       762       763       764       765       766       767  \n",
       "0     0.552972  0.508016 -0.661004  0.648708  0.508159  0.471049  0.812747  \n",
       "1     0.309530  0.539303 -0.772830  0.498029  0.462456  0.497207  0.803436  \n",
       "2     0.497018  0.418673 -0.695262  0.535084  0.468965  0.534107  0.722016  \n",
       "3     0.619413  0.462634 -0.595787  0.625809  0.477340  0.576133  0.758163  \n",
       "4     0.398853  0.552792 -0.693314  0.558638  0.415872  0.535430  0.751466  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "3096  0.401726  0.564576 -0.815372  0.613472  0.482972  0.583095  0.766825  \n",
       "3097  0.464987  0.501455 -0.790398  0.626000  0.466310  0.540599  0.711200  \n",
       "3098  0.577867  0.450494 -0.554175  0.630714  0.495547  0.548192  0.719363  \n",
       "3099  0.479461  0.446085 -0.610415  0.554650  0.437024  0.644774  0.715786  \n",
       "3100  0.491995  0.454371 -0.690442  0.558352  0.457464  0.483374  0.741767  \n",
       "\n",
       "[3101 rows x 768 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "Z_text_df = pd.DataFrame(Z_text_tensor.numpy())\n",
    "Z_text_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9GcFmuNEsVn"
   },
   "source": [
    "## æ¸…æ´—æ•¸æ“šembbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5H23LR9aF0ny"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cb0ed594ba34a05b52791752297863f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3093 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d3f5fdafc9421dba334466a3702baa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/3093 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… å…¨éƒ¨è™•ç†å®Œæˆï¼Œå·²è¼¸å‡º threads_with_embeddings.csv\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "# =============== BERT å‘é‡åµŒå…¥ ===============\n",
    "df = df.dropna(subset=['content']) #è¦å…ˆè™•ç†contentç©ºå€¼æ‰èƒ½embedding\n",
    "# --- è¼‰å…¥ tokenizer & model ---\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-chinese\")\n",
    "model = AutoModel.from_pretrained(\"bert-base-chinese\")\n",
    "# é¸æ“‡ç¡¬é«”è¨­å‚™ï¼ˆMPSã€CUDAã€CPUï¼‰ï¼Œè‡ªå‹•åˆ¤æ–·æ˜¯å¦å¯ç”¨ GPUï¼ˆM1/M2 æ™¶ç‰‡ä¸Šçš„ MPS æˆ– CUDAï¼‰ï¼Œå¦å‰‡ fallback åˆ° CPU\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# --- å»ºç«‹ HuggingFace Dataset ---\n",
    "hf_dataset = Dataset.from_pandas(df[[\"content\"]])\n",
    "\n",
    "# --- tokenize function ---\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples['content'], truncation=True, padding='max_length', max_length=128)\n",
    "tokenized_dataset = hf_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# --- å–å¾— [CLS] å‘é‡ ---\n",
    "def extract_embeddings(batch):\n",
    "    inputs = {k: torch.tensor(v).to(model.device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 0, :].detach().cpu().numpy()\n",
    "    return {\"embeddings\": embeddings}\n",
    "\n",
    "# --- æ‰¹æ¬¡è½‰æ›ç‚º embeddings ---\n",
    "batch_size = 64\n",
    "embeddings_dataset = tokenized_dataset.map(extract_embeddings, batched=True, batch_size=batch_size)\n",
    "\n",
    "# =============== åŒ¯å‡ºæœ€çµ‚çµæœ ===============\n",
    "# embeddings_dataset[\"embeddings\"] æ˜¯ list of 768-dim vectors\n",
    "embedding_df = pd.DataFrame(embeddings_dataset[\"embeddings\"])\n",
    "final_df = pd.concat([df.reset_index(drop=True), embedding_df], axis=1)\n",
    "\n",
    "# å„²å­˜\n",
    "# final_df.to_csv(\"C:/Users/User/Desktop/louis/threads_with_embeddings.csv\",encoding='utf_8_sig', index=False)\n",
    "final_df.to_csv(\"threads_with_embeddings.csv\",encoding='utf_8_sig', index=False)\n",
    "print(\"âœ… å…¨éƒ¨è™•ç†å®Œæˆï¼Œå·²è¼¸å‡º threads_with_embeddings.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WxP6bcNEywY"
   },
   "source": [
    "## åˆ†è©"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "SovtoK069ox_"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/d4/dpw_wc9n69zg41k6pqzpwzcr0000gn/T/jieba.cache\n",
      "Loading model cost 0.258 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'è€ƒå®Œ æœŸä¸­è€ƒ ï¼Œ æˆç¸¾ éƒ½ é‚„æ²’å‡º ä¾† ï¼Œ å°ä¸€ å¥³å…’ å°± è‡ªä¿¡ å° æˆ‘ èªª ï¼š ã€Œ æˆ‘ çœŸç¾¨æ…• å¦³ ç”Ÿ ä¸€å€‹ å¤©æ‰ ï¼ ã€'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = set(['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'ä¹Ÿ', 'èˆ‡', 'æœ‰', 'ç‚º', 'ç­‰'])\n",
    "\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    if not isinstance(text, str):\n",
    "        return ''\n",
    "    words = jieba.cut(text)\n",
    "    words_filtered = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(words_filtered)\n",
    "\n",
    "\n",
    "df['processed_content'] = df['content'].apply(tokenize_and_remove_stopwords)\n",
    "df['processed_content'][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UwCtvYh4E3vU"
   },
   "source": [
    "## æ©Ÿå™¨å­¸ç¿’å»ºæ¨¡"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "eFdTaLb79ovp"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 33647 stored elements and shape (3093, 12887)>\n",
      "  Coords\tValues\n",
      "  (0, 2810)\t0.4662798616255825\n",
      "  (0, 3199)\t0.2941078724734809\n",
      "  (0, 1316)\t0.4428271644129856\n",
      "  (0, 1220)\t0.31033983594608366\n",
      "  (0, 422)\t0.5030766701843938\n",
      "  (0, 902)\t0.3880603079298958\n",
      "  (1, 9706)\t0.44772643118600786\n",
      "  (1, 10484)\t0.44772643118600786\n",
      "  (1, 8824)\t0.25695349239444143\n",
      "  (1, 3502)\t0.425969976146039\n",
      "  (1, 10379)\t0.3887770705954321\n",
      "  (1, 9624)\t0.44772643118600786\n",
      "  (2, 10526)\t0.31144587501432597\n",
      "  (2, 8426)\t0.32887477885054034\n",
      "  (2, 7301)\t0.285391148181221\n",
      "  (2, 12083)\t0.3586696867544276\n",
      "  (2, 6469)\t0.3586696867544276\n",
      "  (2, 6055)\t0.2990798709466531\n",
      "  (2, 10693)\t0.32887477885054034\n",
      "  (2, 9857)\t0.3586696867544276\n",
      "  (2, 3232)\t0.1812649560447855\n",
      "  (2, 5971)\t0.31144587501432597\n",
      "  (3, 1638)\t0.26167811005929115\n",
      "  (3, 548)\t0.23061394459754261\n",
      "  (3, 2710)\t0.3728557459198426\n",
      "  :\t:\n",
      "  (3090, 3045)\t0.4140018744676121\n",
      "  (3090, 3075)\t0.3876142688527415\n",
      "  (3090, 2883)\t0.3657390732966238\n",
      "  (3091, 1638)\t0.23035513728612972\n",
      "  (3091, 702)\t0.20796259097802208\n",
      "  (3091, 2813)\t0.1625400466880004\n",
      "  (3091, 2812)\t0.21359102767160001\n",
      "  (3091, 1405)\t0.22665008839036188\n",
      "  (3091, 2823)\t0.23302350706955696\n",
      "  (3091, 1442)\t0.3163304413126057\n",
      "  (3091, 2883)\t0.2590135719616217\n",
      "  (3091, 2809)\t0.2876720066371137\n",
      "  (3091, 2300)\t0.34498887598809774\n",
      "  (3091, 1570)\t0.34498887598809774\n",
      "  (3091, 2986)\t0.34498887598809774\n",
      "  (3091, 1729)\t0.34498887598809774\n",
      "  (3092, 548)\t0.24995784453429756\n",
      "  (3092, 2838)\t0.2748792874614182\n",
      "  (3092, 2184)\t0.404130889547885\n",
      "  (3092, 3069)\t0.2836276724999312\n",
      "  (3092, 2112)\t0.25162707680971147\n",
      "  (3092, 1179)\t0.404130889547885\n",
      "  (3092, 1431)\t0.32219919619252974\n",
      "  (3092, 3177)\t0.36884482985647593\n",
      "  (3092, 2832)\t0.38948585157415855\n"
     ]
    }
   ],
   "source": [
    "# è¨ˆç®— TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(df['processed_content'])\n",
    "\n",
    "# è¨ˆç®— TF\n",
    "tf_vectorizer = CountVectorizer()\n",
    "tf_matrix = tf_vectorizer.fit_transform(df['processed_content'])\n",
    "\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6wvN8ioFE8Cz"
   },
   "source": [
    "# å¤šæ¨¡å‹åˆ†é¡å¯¦é©—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cROM4E4v9otD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>content_length</th>\n",
       "      <th>lang</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>post_weekday</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_period</th>\n",
       "      <th>viral</th>\n",
       "      <th>post_time</th>\n",
       "      <th>...</th>\n",
       "      <th>post_url</th>\n",
       "      <th>emojis</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>scrape_time_origin</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_exclaim</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_mention</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>processed_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>Thank you God for another day.</td>\n",
       "      <td>30</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:27</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T10:58:39.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@ayofvr/post/DJBymf8uTrK</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:27:40.176749+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Thank   you   God   for   another   day .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼</td>\n",
       "      <td>16</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:27</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-29T12:33:44.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@ban.mei.onnnnni/post/...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:27:54.964788+08:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ç™¾é” ç¿¡éº— ï¼Ÿ   æ²’æœ‰ ä¸‹é™ ç¶²è·¯ ç—…æ…‹ ï¼</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ribboworld2021</td>\n",
       "      <td>è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€</td>\n",
       "      <td>40</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T04:39:46.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@ribboworld2021/post/D...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:09.873641+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>è€ƒå®Œ æœŸä¸­è€ƒ ï¼Œ æˆç¸¾ éƒ½ é‚„æ²’å‡º ä¾† ï¼Œ å°ä¸€ å¥³å…’ å°± è‡ªä¿¡ å° æˆ‘ èªª ï¼š ã€Œ æˆ‘ çœŸ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ayofvr</td>\n",
       "      <td>Just be strong. Confident. Hopeful. Intellectu...</td>\n",
       "      <td>69</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T11:25:22.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@ayofvr/post/DJB1qP5OmzP</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:24.726576+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Just   be   strong .   Confident .   Hopeful ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>jose_ykc</td>\n",
       "      <td>æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€</td>\n",
       "      <td>25</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 06:28</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>6</td>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-29T10:36:19.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@jose_ykc/post/DJBvpGI...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 06:28:39.393706+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>æ—¥æ–‡ è¼”ç³» è€å¸« ä¸Š èª²å…§å®¹ ä¹‹ä¸€ AiScReam   æ­Œè© å°è®€</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3096</th>\n",
       "      <td>leighton.williams</td>\n",
       "      <td>First tasting in California</td>\n",
       "      <td>27</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:23</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 07:30</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@leighton.williams/pos...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:23:40.328046+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>First   tasting   in   California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3097</th>\n",
       "      <td>cape__man</td>\n",
       "      <td>I hoped it would have been better.</td>\n",
       "      <td>34</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:23</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:31</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@cape__man/post/DJAdFd...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:23:55.063517+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I   hoped   it   would   have   been   better .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3098</th>\n",
       "      <td>simimoonlight</td>\n",
       "      <td>I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...</td>\n",
       "      <td>51</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 06:26</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@simimoonlight/post/DJ...</td>\n",
       "      <td>ğŸ«¶ğŸ¿ğŸ¥¹</td>\n",
       "      <td>3</td>\n",
       "      <td>2025-04-30 00:24:39.870994+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>I   can â€™ t   wait   to   watch   Beyonc Ã©   o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3099</th>\n",
       "      <td>other98</td>\n",
       "      <td>Tonight, Canada just proved that they have a h...</td>\n",
       "      <td>77</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 12:31</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@other98/post/DJBGV3NxiX_</td>\n",
       "      <td>ğŸ™Œ</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 00:24:54.669936+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Tonight ,   Canada   just   proved   that   th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3100</th>\n",
       "      <td>scottiebeam</td>\n",
       "      <td>Yall be fighting on here â€¦ i thought threads w...</td>\n",
       "      <td>57</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 00:25</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>night</td>\n",
       "      <td>1</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 01:33</td>\n",
       "      <td>...</td>\n",
       "      <td>https://www.threads.net/@scottiebeam/post/DI_6...</td>\n",
       "      <td></td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 00:25:09.396585+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Yall   be   fighting   on   here   â€¦   i   tho...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3093 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 author                                            content  \\\n",
       "0                ayofvr                     Thank you God for another day.   \n",
       "1                   NaN                                   ç™¾é”ç¿¡éº—ï¼Ÿ æ²’æœ‰ä¸‹é™çš„ç¶²è·¯ç—…æ…‹ï¼   \n",
       "2        ribboworld2021           è€ƒå®ŒæœŸä¸­è€ƒï¼Œæˆç¸¾éƒ½é‚„æ²’å‡ºä¾†ï¼Œå°ä¸€å¥³å…’å°±è‡ªä¿¡çš„å°æˆ‘èªªï¼šã€Œæˆ‘çœŸç¾¨æ…•å¦³ç”Ÿäº†ä¸€å€‹å¤©æ‰ï¼ã€   \n",
       "3                ayofvr  Just be strong. Confident. Hopeful. Intellectu...   \n",
       "4              jose_ykc                          æ—¥æ–‡è¼”ç³»è€å¸«ä¸Šèª²å…§å®¹ä¹‹ä¸€AiScReam æ­Œè©å°è®€   \n",
       "...                 ...                                                ...   \n",
       "3096  leighton.williams                        First tasting in California   \n",
       "3097          cape__man                 I hoped it would have been better.   \n",
       "3098      simimoonlight  I canâ€™t wait to watch BeyoncÃ© on TikTok tonigh...   \n",
       "3099            other98  Tonight, Canada just proved that they have a h...   \n",
       "3100        scottiebeam  Yall be fighting on here â€¦ i thought threads w...   \n",
       "\n",
       "      content_length lang        scrape_time post_weekday  post_hour  \\\n",
       "0                 30   en  2025å¹´04æœˆ30æ—¥ 06:27    Wednesday          6   \n",
       "1                 16   Ch  2025å¹´04æœˆ30æ—¥ 06:27    Wednesday          6   \n",
       "2                 40   Ch  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "3                 69   en  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "4                 25   Ch  2025å¹´04æœˆ30æ—¥ 06:28    Wednesday          6   \n",
       "...              ...  ...                ...          ...        ...   \n",
       "3096              27   en  2025å¹´04æœˆ30æ—¥ 00:23    Wednesday          0   \n",
       "3097              34   en  2025å¹´04æœˆ30æ—¥ 00:23    Wednesday          0   \n",
       "3098              51   en  2025å¹´04æœˆ30æ—¥ 00:24    Wednesday          0   \n",
       "3099              77   en  2025å¹´04æœˆ30æ—¥ 00:24    Wednesday          0   \n",
       "3100              57   en  2025å¹´04æœˆ30æ—¥ 00:25    Wednesday          0   \n",
       "\n",
       "     post_period  viral                 post_time  ...  \\\n",
       "0        morning      0  2025-04-29T10:58:39.000Z  ...   \n",
       "1        morning      1  2025-04-29T12:33:44.000Z  ...   \n",
       "2        morning      0  2025-04-29T04:39:46.000Z  ...   \n",
       "3        morning      0  2025-04-29T11:25:22.000Z  ...   \n",
       "4        morning      1  2025-04-29T10:36:19.000Z  ...   \n",
       "...          ...    ...                       ...  ...   \n",
       "3096       night      0         2025å¹´04æœˆ29æ—¥ 07:30  ...   \n",
       "3097       night      0         2025å¹´04æœˆ29æ—¥ 06:31  ...   \n",
       "3098       night      1         2025å¹´04æœˆ29æ—¥ 06:26  ...   \n",
       "3099       night      1         2025å¹´04æœˆ29æ—¥ 12:31  ...   \n",
       "3100       night      1         2025å¹´04æœˆ29æ—¥ 01:33  ...   \n",
       "\n",
       "                                               post_url emojis  emoji_count  \\\n",
       "0      https://www.threads.net/@ayofvr/post/DJBymf8uTrK                   0   \n",
       "1     https://www.threads.net/@ban.mei.onnnnni/post/...                   0   \n",
       "2     https://www.threads.net/@ribboworld2021/post/D...                   0   \n",
       "3      https://www.threads.net/@ayofvr/post/DJB1qP5OmzP                   0   \n",
       "4     https://www.threads.net/@jose_ykc/post/DJBvpGI...                   0   \n",
       "...                                                 ...    ...          ...   \n",
       "3096  https://www.threads.net/@leighton.williams/pos...                   0   \n",
       "3097  https://www.threads.net/@cape__man/post/DJAdFd...                   0   \n",
       "3098  https://www.threads.net/@simimoonlight/post/DJ...    ğŸ«¶ğŸ¿ğŸ¥¹            3   \n",
       "3099  https://www.threads.net/@other98/post/DJBGV3NxiX_      ğŸ™Œ            1   \n",
       "3100  https://www.threads.net/@scottiebeam/post/DI_6...                   0   \n",
       "\n",
       "                   scrape_time_origin  has_question  has_exclaim  has_url  \\\n",
       "0    2025-04-30 06:27:40.176749+08:00         False        False    False   \n",
       "1    2025-04-30 06:27:54.964788+08:00          True         True    False   \n",
       "2    2025-04-30 06:28:09.873641+08:00         False         True    False   \n",
       "3    2025-04-30 06:28:24.726576+08:00         False        False    False   \n",
       "4    2025-04-30 06:28:39.393706+08:00         False        False    False   \n",
       "...                               ...           ...          ...      ...   \n",
       "3096 2025-04-30 00:23:40.328046+08:00         False        False    False   \n",
       "3097 2025-04-30 00:23:55.063517+08:00         False        False    False   \n",
       "3098 2025-04-30 00:24:39.870994+08:00         False        False    False   \n",
       "3099 2025-04-30 00:24:54.669936+08:00         False         True    False   \n",
       "3100 2025-04-30 00:25:09.396585+08:00         False        False    False   \n",
       "\n",
       "      has_mention  has_hashtag  \\\n",
       "0           False        False   \n",
       "1           False        False   \n",
       "2           False        False   \n",
       "3           False        False   \n",
       "4           False        False   \n",
       "...           ...          ...   \n",
       "3096        False        False   \n",
       "3097        False        False   \n",
       "3098        False        False   \n",
       "3099        False        False   \n",
       "3100        False        False   \n",
       "\n",
       "                                      processed_content  \n",
       "0             Thank   you   God   for   another   day .  \n",
       "1                               ç™¾é” ç¿¡éº— ï¼Ÿ   æ²’æœ‰ ä¸‹é™ ç¶²è·¯ ç—…æ…‹ ï¼  \n",
       "2     è€ƒå®Œ æœŸä¸­è€ƒ ï¼Œ æˆç¸¾ éƒ½ é‚„æ²’å‡º ä¾† ï¼Œ å°ä¸€ å¥³å…’ å°± è‡ªä¿¡ å° æˆ‘ èªª ï¼š ã€Œ æˆ‘ çœŸ...  \n",
       "3     Just   be   strong .   Confident .   Hopeful ....  \n",
       "4                    æ—¥æ–‡ è¼”ç³» è€å¸« ä¸Š èª²å…§å®¹ ä¹‹ä¸€ AiScReam   æ­Œè© å°è®€  \n",
       "...                                                 ...  \n",
       "3096                  First   tasting   in   California  \n",
       "3097    I   hoped   it   would   have   been   better .  \n",
       "3098  I   can â€™ t   wait   to   watch   Beyonc Ã©   o...  \n",
       "3099  Tonight ,   Canada   just   proved   that   th...  \n",
       "3100  Yall   be   fighting   on   here   â€¦   i   tho...  \n",
       "\n",
       "[3093 rows x 30 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, random_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 8\n",
    "num_epochs = 5\n",
    "# ========== åƒæ•¸è¨­å®š ==========\n",
    "model_tokenizer_map = {\n",
    "    \"FusionMacBERT\": \"hfl/chinese-macbert-base\",\n",
    "    \"PureMacBERT\": \"hfl/chinese-macbert-base\",\n",
    "    \"NumericOnly\": None,\n",
    "    \"BiLSTMWithNumeric\": \"bert-base-chinese\",\n",
    "    \"MacBERTWithGRU\": \"hfl/chinese-macbert-base\",\n",
    "    \"MacBERTMLPFusion\": \"hfl/chinese-macbert-base\",\n",
    "    \"TextCNNMacBERT\": \"hfl/chinese-macbert-base\",\n",
    "    \"RoBERTa\": \"hfl/chinese-roberta-wwm-ext\",\n",
    "    \"BERTwwmExt\": \"hfl/chinese-bert-wwm-ext\",\n",
    "    \"ERNIE\": \"nghuyong/ernie-3.0-base-zh\",\n",
    "    \"ConvBERT\": \"YituTech/conv-bert-base\"\n",
    "}\n",
    "\n",
    "#tokenizer\n",
    "default_tokenizer_name = model_tokenizer_map[\"FusionMacBERT\"]\n",
    "tokenizer = AutoTokenizer.from_pretrained(default_tokenizer_name)\n",
    "\n",
    "#è¼‰å…¥è³‡æ–™\n",
    "# df = pd.read_csv(\"C:/Users/User/Desktop/louis/threads_cleaned_v2.csv\", encoding='utf_8_sig')\n",
    "#df = df.dropna(subset=['content', 'view_count']).reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "To77Vfki2Jzf"
   },
   "source": [
    "# Label åˆ†ç¾¤ (ç”¨å››åˆ†ä½æ•¸åˆ†ä¸‰ç¾¤)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Df9cfTOt9oqs"
   },
   "outputs": [],
   "source": [
    "# Label åˆ†ç¾¤ ï¼šæ¨™ç±¤è½‰æ›ï¼ˆæŒ‰ç€è¦½æ•¸é€²è¡Œåˆ†ç¾¤ï¼‰\n",
    "# å–ã€Œç€è¦½æ•¸ã€çš„ç¬¬ 80 ç™¾åˆ†ä½ä½œç‚ºé«˜äººæ°£é–€æª»ï¼ˆq_highï¼‰ã€ç¬¬ 20 ç™¾åˆ†ä½ä½œç‚ºä½äººæ°£é–€æª»ï¼ˆq_lowï¼‰\n",
    "# æŠŠæ¯ç­†è³‡æ–™çš„ã€Œview_countã€åŠƒåˆ†ç‚ºä¸‰é¡ï¼š0 é«˜äººæ°£ (high)ã€1 ä¸­äººæ°£ (medium)ã€2 ä½äººæ°£ (low)\n",
    "q_high = df['view_count'].quantile(0.80)\n",
    "q_low = df['view_count'].quantile(0.20)\n",
    "df['view_class'] = df['view_count'].apply(lambda x: \"high\" if x >= q_high else (\"low\" if x <= q_low else \"medium\"))\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['view_class'])\n",
    "\n",
    "#åš oversampling é¡åˆ¥è³‡æ–™å¹³è¡¡ ï¼šè³‡æ–™å¢å¼·ï¼ˆé‡å° high / low é¡åˆ¥ oversampleï¼‰\n",
    "df_high = df[df['view_class'] == 'high']\n",
    "df_low = df[df['view_class'] == 'low']\n",
    "df_medium = df[df['view_class'] == 'medium']\n",
    "\n",
    "# åˆ†åˆ¥å–å‡ºä¸‰å€‹åˆ†é¡çš„æ¨£æœ¬ï¼šå° high èˆ‡ low åˆ†é¡åšã€Œéæ¡æ¨£ã€ï¼Œå„è‡ªè¤‡è£½ä¸‰æ¬¡ï¼Œè®“è³‡æ–™æ•¸é‡æ¥è¿‘ medium\n",
    "# å†å°æ•´å€‹è³‡æ–™è¡¨åšéš¨æ©Ÿæ‰“æ•£ (shuffleï¼‰ï¼Œé¿å…æ¨¡å‹å­¸åˆ°è³‡æ–™é †åºçš„åèª¤\n",
    "df_high_oversampled = pd.concat([df_high] * 3, ignore_index=True)\n",
    "df_low_oversampled = pd.concat([df_low] * 3, ignore_index=True)\n",
    "df = pd.concat([df_medium, df_high_oversampled, df_low_oversampled], ignore_index=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-d1A_HlMu8Ae"
   },
   "outputs": [],
   "source": [
    "q_high"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HOiJNmCmu_uf"
   },
   "outputs": [],
   "source": [
    "q_low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ibbctyH9CUzu"
   },
   "source": [
    "## Label åˆ†ç¾¤ ï¼ˆ1000ä»¥ä¸‹ã€1000~10000ã€10000~100000ã€100000ä»¥ä¸Š)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5yL13rSfCUzu"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>content_length</th>\n",
       "      <th>lang</th>\n",
       "      <th>scrape_time</th>\n",
       "      <th>post_weekday</th>\n",
       "      <th>post_hour</th>\n",
       "      <th>post_period</th>\n",
       "      <th>viral</th>\n",
       "      <th>post_time</th>\n",
       "      <th>...</th>\n",
       "      <th>emoji_count</th>\n",
       "      <th>scrape_time_origin</th>\n",
       "      <th>has_question</th>\n",
       "      <th>has_exclaim</th>\n",
       "      <th>has_url</th>\n",
       "      <th>has_mention</th>\n",
       "      <th>has_hashtag</th>\n",
       "      <th>processed_content</th>\n",
       "      <th>view_class</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>031758_wu</td>\n",
       "      <td>è€å¯¦èªªæˆ‘ç¾åœ¨é‚„æ˜¯æä¸æ‡‚ä¸€å ´æ¼”å”±æœƒæ¶é€™éº¼å¤šæ¬¡ç¥¨çš„æ„ç¾©åœ¨å“ªè£¡ğŸ’§</td>\n",
       "      <td>29</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 08:30</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>8</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29T12:59:30.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-30 08:30:58.388029+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>è€å¯¦ èªª æˆ‘ç¾ é‚„æ˜¯ æä¸æ‡‚ ä¸€å ´ æ¼”å”± æœƒ æ¶ é€™éº¼ å¤šæ¬¡ ç¥¨ æ„ç¾©åœ¨ å“ªè£¡ ğŸ’§</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>yuii_1.6</td>\n",
       "      <td>å³æµ·å«„ğŸ«§èªªèƒ½çœ‹åˆ°å¾ˆå¤šæ©ç‘Ÿå¾ˆé–‹å¿ƒé‚„èªªå°åŒ—çš„æ‡‰æ´æ³•å¤ªè®šäº† ã… ã… </td>\n",
       "      <td>29</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 02:17</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ28æ—¥ 02:23</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-29 02:17:59.586251+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>å³æµ· å«„ ğŸ«§ èªª èƒ½ çœ‹åˆ° å¾ˆå¤š æ©ç‘Ÿ å¾ˆ é–‹å¿ƒ é‚„èªª å°åŒ— æ‡‰æ´æ³• å¤ª è®š   ã…  ã… </td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rejiya1575</td>\n",
       "      <td>Tahajjud is life changer. â™¥</td>\n",
       "      <td>27</td>\n",
       "      <td>lg</td>\n",
       "      <td>2025å¹´04æœˆ28æ—¥ 05:19</td>\n",
       "      <td>Monday</td>\n",
       "      <td>5</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ27æ—¥ 18:08</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-04-28 05:19:53.327702+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Tahajjud   is   life   changer .   â™¥</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jonblta</td>\n",
       "      <td>i dont wanna hear Warriors fans complaining ab...</td>\n",
       "      <td>87</td>\n",
       "      <td>en</td>\n",
       "      <td>2025å¹´05æœˆ03æ—¥ 19:29</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>19</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-03T03:09:05.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-03 19:29:20.954467+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>i   dont   wanna   hear   Warriors   fans   co...</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_lync.m</td>\n",
       "      <td>Tráº£i nghiá»‡m Ä‘áº§u tiÃªn khi Ä‘u Em Xinh: Yeolan vÃ ...</td>\n",
       "      <td>80</td>\n",
       "      <td>vi</td>\n",
       "      <td>2025å¹´05æœˆ03æ—¥ 08:40</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>8</td>\n",
       "      <td>morning</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-02T11:43:24.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-03 08:40:12.796089+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Tr áº£ i   nghi á»‡ m   Ä‘ áº§ u   ti Ãª n   khi   Ä‘ u...</td>\n",
       "      <td>high</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6222</th>\n",
       "      <td>jauyiwu</td>\n",
       "      <td>é€£çºŒä¸‰å¤©èµ°åœ¨è·¯ä¸Šï¼Œè½åˆ°ä¸åŒçš„äººèªªè¦å»ç™½æ²™å±¯ã€‚ï¿¼æˆ‘æƒ³ï¼Œé€™å·²ç¶“è®Šæˆå°ç£äººä¸€å€‹æ–°çš„æ™‚é–“é«”æ„Ÿï¼Œå°±å¥½åƒ...</td>\n",
       "      <td>57</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´05æœˆ01æ—¥ 17:40</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>17</td>\n",
       "      <td>evening</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-01T00:46:32.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-05-01 17:40:50.710474+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>é€£çºŒ ä¸‰å¤© èµ° è·¯ä¸Š ï¼Œ è½åˆ° ä¸åŒ äºº èªª è¦ å» ç™½æ²™ å±¯ ã€‚ ï¿¼ æˆ‘ æƒ³ ï¼Œ é€™å·² ç¶“...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6223</th>\n",
       "      <td>__mi_achool</td>\n",
       "      <td>æ”¶åˆ°vip äº† åŸåƒ¹è®“ä¸€å¼µ A2 2XX</td>\n",
       "      <td>20</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 07:25</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>7</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ28æ—¥ 17:58</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 07:25:02.893557+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>æ”¶åˆ° vip     åŸåƒ¹ è®“ ä¸€å¼µ   A2   2XX</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6224</th>\n",
       "      <td>lhs_7632</td>\n",
       "      <td>åˆ†æ‰‹ç¬¬åå…«å¤© å¶ç„¶çœ‹è¦‹ä½ çš„é™æ™‚å‹•æ…‹ï¼Œé€™æ˜¯åå…«å¤©å…§æ›çš„ç¬¬äºŒå€‹ç”·ç”Ÿäº†ï¼Œæ‰“é–‹äº†ä½ è¿½è¹¤åå–® ä¸ç®¡æ˜¯æˆ‘...</td>\n",
       "      <td>124</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ30æ—¥ 07:03</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>7</td>\n",
       "      <td>morning</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-28T22:51:13.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30 07:03:46.817921+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>åˆ†æ‰‹ ç¬¬åå…«å¤©   å¶ç„¶ çœ‹è¦‹ ä½  é™æ™‚ å‹•æ…‹ ï¼Œ é€™æ˜¯ åå…«å¤© å…§æ› ç¬¬äºŒ å€‹ ç”·ç”Ÿ ï¼Œ ...</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>taro_puree_05</td>\n",
       "      <td>æˆ‘æœ‰èªªæˆ‘è¦å»å— ä½ å°±çµ¦æˆ‘ç¬¬ä¸€æ’çš„ç¥¨ è™«åˆâ“</td>\n",
       "      <td>21</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´05æœˆ01æ—¥ 03:09</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>3</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-30T05:43:31.000Z</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-05-01 03:09:51.931280+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>æˆ‘ èªª æˆ‘ è¦ å» å—   ä½  å°±çµ¦ æˆ‘ ç¬¬ä¸€æ’ ç¥¨   è™«åˆ â“</td>\n",
       "      <td>medium</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>xuan._0603</td>\n",
       "      <td>æ¼”å”±æœƒé‡åˆ°æœ€é åŒ—çš„äº‹ï¼š éŒ„åˆ°æœ€å–œæ­¡çš„partæ‰‹æ©Ÿè·³å„²å­˜ç©ºé–“ä¸è¶³ã€‚</td>\n",
       "      <td>32</td>\n",
       "      <td>Ch</td>\n",
       "      <td>2025å¹´04æœˆ29æ—¥ 02:44</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2</td>\n",
       "      <td>night</td>\n",
       "      <td>0</td>\n",
       "      <td>2025å¹´04æœˆ28æ—¥ 12:45</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-04-29 02:44:28.814612+08:00</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>æ¼”å”± æœƒ é‡åˆ° æœ€ é åŒ— äº‹ ï¼š   éŒ„åˆ° æœ€ å–œæ­¡ part æ‰‹æ©Ÿ è·³ å„²å­˜ ç©ºé–“ ä¸è¶³ ã€‚</td>\n",
       "      <td>low</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6227 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             author                                            content  \\\n",
       "0         031758_wu                      è€å¯¦èªªæˆ‘ç¾åœ¨é‚„æ˜¯æä¸æ‡‚ä¸€å ´æ¼”å”±æœƒæ¶é€™éº¼å¤šæ¬¡ç¥¨çš„æ„ç¾©åœ¨å“ªè£¡ğŸ’§   \n",
       "1          yuii_1.6                      å³æµ·å«„ğŸ«§èªªèƒ½çœ‹åˆ°å¾ˆå¤šæ©ç‘Ÿå¾ˆé–‹å¿ƒé‚„èªªå°åŒ—çš„æ‡‰æ´æ³•å¤ªè®šäº† ã… ã…    \n",
       "2        rejiya1575                        Tahajjud is life changer. â™¥   \n",
       "3           jonblta  i dont wanna hear Warriors fans complaining ab...   \n",
       "4           _lync.m  Tráº£i nghiá»‡m Ä‘áº§u tiÃªn khi Ä‘u Em Xinh: Yeolan vÃ ...   \n",
       "...             ...                                                ...   \n",
       "6222        jauyiwu  é€£çºŒä¸‰å¤©èµ°åœ¨è·¯ä¸Šï¼Œè½åˆ°ä¸åŒçš„äººèªªè¦å»ç™½æ²™å±¯ã€‚ï¿¼æˆ‘æƒ³ï¼Œé€™å·²ç¶“è®Šæˆå°ç£äººä¸€å€‹æ–°çš„æ™‚é–“é«”æ„Ÿï¼Œå°±å¥½åƒ...   \n",
       "6223    __mi_achool                               æ”¶åˆ°vip äº† åŸåƒ¹è®“ä¸€å¼µ A2 2XX   \n",
       "6224       lhs_7632  åˆ†æ‰‹ç¬¬åå…«å¤© å¶ç„¶çœ‹è¦‹ä½ çš„é™æ™‚å‹•æ…‹ï¼Œé€™æ˜¯åå…«å¤©å…§æ›çš„ç¬¬äºŒå€‹ç”·ç”Ÿäº†ï¼Œæ‰“é–‹äº†ä½ è¿½è¹¤åå–® ä¸ç®¡æ˜¯æˆ‘...   \n",
       "6225  taro_puree_05                              æˆ‘æœ‰èªªæˆ‘è¦å»å— ä½ å°±çµ¦æˆ‘ç¬¬ä¸€æ’çš„ç¥¨ è™«åˆâ“   \n",
       "6226     xuan._0603                   æ¼”å”±æœƒé‡åˆ°æœ€é åŒ—çš„äº‹ï¼š éŒ„åˆ°æœ€å–œæ­¡çš„partæ‰‹æ©Ÿè·³å„²å­˜ç©ºé–“ä¸è¶³ã€‚   \n",
       "\n",
       "      content_length lang        scrape_time post_weekday  post_hour  \\\n",
       "0                 29   Ch  2025å¹´04æœˆ30æ—¥ 08:30    Wednesday          8   \n",
       "1                 29   Ch  2025å¹´04æœˆ29æ—¥ 02:17      Tuesday          2   \n",
       "2                 27   lg  2025å¹´04æœˆ28æ—¥ 05:19       Monday          5   \n",
       "3                 87   en  2025å¹´05æœˆ03æ—¥ 19:29     Saturday         19   \n",
       "4                 80   vi  2025å¹´05æœˆ03æ—¥ 08:40     Saturday          8   \n",
       "...              ...  ...                ...          ...        ...   \n",
       "6222              57   Ch  2025å¹´05æœˆ01æ—¥ 17:40     Thursday         17   \n",
       "6223              20   Ch  2025å¹´04æœˆ29æ—¥ 07:25      Tuesday          7   \n",
       "6224             124   Ch  2025å¹´04æœˆ30æ—¥ 07:03    Wednesday          7   \n",
       "6225              21   Ch  2025å¹´05æœˆ01æ—¥ 03:09     Thursday          3   \n",
       "6226              32   Ch  2025å¹´04æœˆ29æ—¥ 02:44      Tuesday          2   \n",
       "\n",
       "     post_period  viral                 post_time  ... emoji_count  \\\n",
       "0        morning      0  2025-04-29T12:59:30.000Z  ...           1   \n",
       "1          night      0         2025å¹´04æœˆ28æ—¥ 02:23  ...           1   \n",
       "2        morning      0         2025å¹´04æœˆ27æ—¥ 18:08  ...           1   \n",
       "3        evening      0  2025-05-03T03:09:05.000Z  ...           0   \n",
       "4        morning      1  2025-05-02T11:43:24.000Z  ...           0   \n",
       "...          ...    ...                       ...  ...         ...   \n",
       "6222     evening      0  2025-05-01T00:46:32.000Z  ...           0   \n",
       "6223     morning      0         2025å¹´04æœˆ28æ—¥ 17:58  ...           0   \n",
       "6224     morning      0  2025-04-28T22:51:13.000Z  ...           0   \n",
       "6225       night      0  2025-04-30T05:43:31.000Z  ...           1   \n",
       "6226       night      0         2025å¹´04æœˆ28æ—¥ 12:45  ...           0   \n",
       "\n",
       "                   scrape_time_origin  has_question  has_exclaim  has_url  \\\n",
       "0    2025-04-30 08:30:58.388029+08:00         False        False    False   \n",
       "1    2025-04-29 02:17:59.586251+08:00         False        False    False   \n",
       "2    2025-04-28 05:19:53.327702+08:00         False        False    False   \n",
       "3    2025-05-03 19:29:20.954467+08:00         False        False    False   \n",
       "4    2025-05-03 08:40:12.796089+08:00         False        False    False   \n",
       "...                               ...           ...          ...      ...   \n",
       "6222 2025-05-01 17:40:50.710474+08:00         False        False    False   \n",
       "6223 2025-04-29 07:25:02.893557+08:00         False        False    False   \n",
       "6224 2025-04-30 07:03:46.817921+08:00         False        False    False   \n",
       "6225 2025-05-01 03:09:51.931280+08:00         False        False    False   \n",
       "6226 2025-04-29 02:44:28.814612+08:00         False        False    False   \n",
       "\n",
       "      has_mention  has_hashtag  \\\n",
       "0           False        False   \n",
       "1           False        False   \n",
       "2           False        False   \n",
       "3           False        False   \n",
       "4           False        False   \n",
       "...           ...          ...   \n",
       "6222        False        False   \n",
       "6223        False        False   \n",
       "6224        False        False   \n",
       "6225        False        False   \n",
       "6226        False        False   \n",
       "\n",
       "                                      processed_content  view_class  label  \n",
       "0             è€å¯¦ èªª æˆ‘ç¾ é‚„æ˜¯ æä¸æ‡‚ ä¸€å ´ æ¼”å”± æœƒ æ¶ é€™éº¼ å¤šæ¬¡ ç¥¨ æ„ç¾©åœ¨ å“ªè£¡ ğŸ’§         low      1  \n",
       "1          å³æµ· å«„ ğŸ«§ èªª èƒ½ çœ‹åˆ° å¾ˆå¤š æ©ç‘Ÿ å¾ˆ é–‹å¿ƒ é‚„èªª å°åŒ— æ‡‰æ´æ³• å¤ª è®š   ã…  ã…       medium      2  \n",
       "2                  Tahajjud   is   life   changer .   â™¥         low      1  \n",
       "3     i   dont   wanna   hear   Warriors   fans   co...         low      1  \n",
       "4     Tr áº£ i   nghi á»‡ m   Ä‘ áº§ u   ti Ãª n   khi   Ä‘ u...        high      0  \n",
       "...                                                 ...         ...    ...  \n",
       "6222  é€£çºŒ ä¸‰å¤© èµ° è·¯ä¸Š ï¼Œ è½åˆ° ä¸åŒ äºº èªª è¦ å» ç™½æ²™ å±¯ ã€‚ ï¿¼ æˆ‘ æƒ³ ï¼Œ é€™å·² ç¶“...      medium      2  \n",
       "6223                      æ”¶åˆ° vip     åŸåƒ¹ è®“ ä¸€å¼µ   A2   2XX         low      1  \n",
       "6224  åˆ†æ‰‹ ç¬¬åå…«å¤©   å¶ç„¶ çœ‹è¦‹ ä½  é™æ™‚ å‹•æ…‹ ï¼Œ é€™æ˜¯ åå…«å¤© å…§æ› ç¬¬äºŒ å€‹ ç”·ç”Ÿ ï¼Œ ...      medium      2  \n",
       "6225                  æˆ‘ èªª æˆ‘ è¦ å» å—   ä½  å°±çµ¦ æˆ‘ ç¬¬ä¸€æ’ ç¥¨   è™«åˆ â“      medium      2  \n",
       "6226    æ¼”å”± æœƒ é‡åˆ° æœ€ é åŒ— äº‹ ï¼š   éŒ„åˆ° æœ€ å–œæ­¡ part æ‰‹æ©Ÿ è·³ å„²å­˜ ç©ºé–“ ä¸è¶³ ã€‚         low      1  \n",
       "\n",
       "[6227 rows x 32 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# å°‡ view_count åˆ†æˆå››é¡ï¼š\n",
    "# 0: å°æ–¼ 1000\n",
    "# 1: 1000 ~ 9999\n",
    "# 2: 10000 ~ 99999\n",
    "# 3: 100000 ä»¥ä¸Š\n",
    "\n",
    "def map_view_class(x):\n",
    "    if x < 1000:\n",
    "        return 'low'\n",
    "    elif x < 10000:\n",
    "        return 'medium'\n",
    "    elif x < 100000:\n",
    "        return 'high'\n",
    "    else:\n",
    "        return 'very_high'\n",
    "\n",
    "df['view_class'] = df['view_count'].apply(map_view_class)\n",
    "\n",
    "# ç·¨ç¢¼æˆæ•¸å­— label\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['view_class'])\n",
    "\n",
    "df_high = df[df['view_class'] == 'very_high']\n",
    "df_medium = df[df['view_class'] == 'high']\n",
    "df_low = df[df['view_class'] == 'medium']\n",
    "df_very_low = df[df['view_class'] == 'low']\n",
    "\n",
    "# é‡å°è¼ƒå°‘çš„é¡åˆ¥é€²è¡Œæ“´å¢ï¼ˆå‡è¨­ high å’Œ very_low æ¯”è¼ƒå°‘ï¼‰\n",
    "df_high_oversampled = pd.concat([df_high] * 3, ignore_index=True)\n",
    "df_very_low_oversampled = pd.concat([df_very_low] * 3, ignore_index=True)\n",
    "\n",
    "# åˆä½µä¸¦æ‰“äº‚\n",
    "df = pd.concat([df_medium, df_low, df_high_oversampled, df_very_low_oversampled], ignore_index=True)\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j32CLLcICUzu"
   },
   "outputs": [],
   "source": [
    "class RegressionDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = df['input_ids'].tolist()\n",
    "        self.attention_mask = df['attention_mask'].tolist()\n",
    "        self.numerics = df[num_cols].values\n",
    "        self.targets = df['target'].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "            'numerics': torch.tensor(self.numerics[idx], dtype=torch.float),\n",
    "            'target': torch.tensor(self.targets[idx], dtype=torch.float)\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UeqEslof2OBB"
   },
   "source": [
    "# Normalization æ•¸å€¼ç‰¹å¾µæ¨™æº–åŒ–"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "N3pJMu-g9on2"
   },
   "outputs": [],
   "source": [
    "# Normalization æ•¸å€¼ç‰¹å¾µæ¨™æº–åŒ–\n",
    "base_num_cols = ['like_count', 'share_count', 'repost_count', 'reply_count', 'emoji_count', 'has_photo', 'has_video', 'has_question', 'has_exclaim', 'has_mention', 'has_url', 'has_hashtag', 'content_length']\n",
    "# æ‰¾å‡º one-hot ç·¨ç¢¼çš„æ¬„ä½ï¼ˆèªè¨€é¡å‹ã€ç™¼æ–‡æ™‚æ®µã€æ˜ŸæœŸå¹¾ç­‰é¡åˆ¥æ¬„ä½ï¼‰\n",
    "# ä½¿ç”¨ StandardScaler å°‡æ•¸å€¼æ¬„ä½è½‰æ›ç‚ºã€Œæ¨™æº–å¸¸æ…‹åˆ†å¸ƒã€ï¼ˆmean=0, std=1ï¼‰ï¼Œæœ‰åŠ©æ–¼æ¨¡å‹å­¸ç¿’ç©©å®šã€‚\n",
    "onehot_cols = [col for col in df.columns if col.startswith('lang_') or col.startswith('post_period_') or col.startswith('post_weekday_')]\n",
    "num_cols = base_num_cols + onehot_cols\n",
    "scaler = StandardScaler()\n",
    "df[num_cols] = scaler.fit_transform(df[num_cols])\n",
    "\n",
    "# Tokenizer æ–‡æœ¬ç·¨ç¢¼ ï¼šä½¿ç”¨äº‹å…ˆå®šç¾©å¥½çš„ tokenizerï¼ˆä¾‹å¦‚ MacBERTã€RoBERTaï¼‰å°è²¼æ–‡é€²è¡Œæ–·è©ã€ç·¨ç¢¼\n",
    "# å°‡ç·¨ç¢¼å¾Œçš„çµæœå„²å­˜åˆ° df ä¸­ï¼Œé€™å…©å€‹æ¬„ä½æœƒä½œç‚º BERT æ¨¡å‹çš„è¼¸å…¥\n",
    "encodings = tokenizer(df['content'].tolist(), truncation=True, padding='max_length', max_length=128)\n",
    "df['input_ids'] = encodings['input_ids']  # æ–·è©å¾Œå°æ‡‰çš„è©å½™ ID\n",
    "df['attention_mask'] = encodings['attention_mask']  # å°æ‡‰ä½ç½®æ˜¯å¦æ˜¯ paddingï¼ˆ0ï¼‰æˆ–å¯¦éš›å…§å®¹ï¼ˆ1ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZsA6q_qf9ojJ"
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4OBPv79a10W0"
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = df['input_ids'].tolist()\n",
    "        self.attention_mask = df['attention_mask'].tolist()\n",
    "        self.labels = df['label'].tolist()\n",
    "        self.numerics = df[num_cols].values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "            'numerics': torch.tensor(self.numerics[idx], dtype=torch.float),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_iVSfG82Gpt"
   },
   "source": [
    "#æ¨¡å‹æ¶æ§‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "um-YKfVt10Uf"
   },
   "outputs": [],
   "source": [
    "#æ¨¡å‹æ¶æ§‹\n",
    "# 1. FusionMacBERTï¼šBERT + æ•¸å€¼ç‰¹å¾µ concat\n",
    "class FusionMacBERTModel(nn.Module):\n",
    "    def __init__(self, model_name, num_numeric_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.numeric_fc = nn.Linear(num_numeric_features, 64)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size + 64, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerics):\n",
    "        cls_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        num_out = torch.relu(self.numeric_fc(numerics))\n",
    "        combined = torch.cat((cls_output, num_out), dim=1)\n",
    "        return self.classifier(self.dropout(combined))\n",
    "\n",
    "# 2. PureMacBERTï¼šåªæœ‰æ–‡å­—\n",
    "class PureMacBERTModel(nn.Module):\n",
    "    def __init__(self, model_name, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(self.bert.config.hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerics=None):\n",
    "        cls_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        return self.classifier(self.dropout(cls_output))\n",
    "\n",
    "# 3. NumericOnlyï¼šåªæœ‰æ•¸å€¼ç‰¹å¾µ\n",
    "class NumericOnlyModel(nn.Module):\n",
    "    def __init__(self, num_numeric_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_numeric_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, numerics=None):\n",
    "        return self.classifier(numerics)\n",
    "\n",
    "# 4. BiLSTMWithNumericï¼šLSTM è™•ç†è©åµŒå…¥ + æ•¸å€¼ç‰¹å¾µ\n",
    "class BiLSTMWithNumeric(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_numeric_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.numeric_fc = nn.Linear(num_numeric_features, 64)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.classifier = nn.Linear(hidden_dim * 2 + 64, num_classes)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerics):\n",
    "        x = self.embedding(input_ids)\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        pooled = lstm_out[:, -1, :]\n",
    "        num_out = torch.relu(self.numeric_fc(numerics))\n",
    "        combined = torch.cat((pooled, num_out), dim=1)\n",
    "        return self.classifier(self.dropout(combined))\n",
    "\n",
    "# 5. MacBERTWithGRUï¼šBERT + GRU + æ•¸å€¼ç‰¹å¾µ\n",
    "class MacBERTWithGRU(nn.Module):\n",
    "    def __init__(self, model_name, num_numeric_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.gru = nn.GRU(self.bert.config.hidden_size, 128, batch_first=True, bidirectional=True)\n",
    "        self.numeric_fc = nn.Linear(num_numeric_features, 64)\n",
    "        self.classifier = nn.Linear(128*2 + 64, num_classes)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerics):\n",
    "        bert_out = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state\n",
    "        gru_out, _ = self.gru(bert_out)\n",
    "        pooled = gru_out[:, -1, :]\n",
    "        num_out = torch.relu(self.numeric_fc(numerics))\n",
    "        combined = torch.cat((pooled, num_out), dim=1)\n",
    "        return self.classifier(self.dropout(combined))\n",
    "\n",
    "# 6. MacBERTMLPFusionï¼šBERT + æ•¸å€¼ç‰¹å¾µ -> MLP\n",
    "class MacBERTMLPFusion(nn.Module):\n",
    "    def __init__(self, model_name, num_numeric_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(self.bert.config.hidden_size + num_numeric_features, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerics):\n",
    "        cls_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        combined = torch.cat((cls_output, numerics), dim=1)\n",
    "        return self.fc(combined)\n",
    "\n",
    "# 7. TextCNNMacBERTï¼šBERT è¼¸å‡ºå·ç©å¾Œ + æ•¸å€¼ç‰¹å¾µ\n",
    "class TextCNNMacBERT(nn.Module):\n",
    "    def __init__(self, model_name, num_numeric_features, num_classes):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.convs = nn.ModuleList([nn.Conv2d(1, 64, (k, self.bert.config.hidden_size)) for k in [2, 3, 4]])\n",
    "        self.numeric_fc = nn.Linear(num_numeric_features, 64)\n",
    "        self.classifier = nn.Linear(64 * len([2, 3, 4]) + 64, num_classes)\n",
    "\n",
    "    def conv_and_pool(self, x, conv):\n",
    "        x = torch.relu(conv(x)).squeeze(3)\n",
    "        x = torch.max_pool1d(x, x.size(2)).squeeze(2)\n",
    "        return x\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerics):\n",
    "        x = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state.unsqueeze(1)\n",
    "        cnn_out = torch.cat([self.conv_and_pool(x, conv) for conv in self.convs], 1)\n",
    "        num_out = torch.relu(self.numeric_fc(numerics))\n",
    "        combined = torch.cat((cnn_out, num_out), dim=1)\n",
    "        return self.classifier(combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "De3g_-Qs2Vux"
   },
   "outputs": [],
   "source": [
    "#è¨“ç·´èˆ‡è©•ä¼°\n",
    "def train_and_eval(model, name, preview_count=10):\n",
    "    model = model.to(torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"))\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "    loss_fn = FocalLoss()\n",
    "    # loss_fn = nn.MSELoss()\n",
    "\n",
    "    # è¨“ç·´éšæ®µ\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            numerics = batch['numerics'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            output = model(input_ids, attention_mask, numerics)\n",
    "            loss = loss_fn(output, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # è©•ä¼°éšæ®µ\n",
    "    model.eval()\n",
    "    all_preds, all_labels = [], []\n",
    "    '''\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            numerics = batch['numerics'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            output = model(input_ids, attention_mask, numerics)\n",
    "            preds = output.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    mse = mean_squared_error(all_targets, all_preds)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    print(f\"[{name} è©•ä¼°çµæœ] MSE: {mse:.2f} | MAE: {mae:.2f}\")\n",
    "    print(f\"\\n{name} è©•ä¼°çµæœï¼š\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))\n",
    "    '''\n",
    "    preview_shown = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            numerics = batch['numerics'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            output = model(input_ids, attention_mask, numerics)\n",
    "            preds = output.argmax(dim=1).cpu().numpy()\n",
    "            all_preds.extend(preds)\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "            #å°å‡ºå‰å¹¾ç­†çš„é æ¸¬ã€çœŸå¯¦å€¼\n",
    "            if preview_shown < preview_count:\n",
    "                batch_size = input_ids.shape[0]\n",
    "                for i in range(batch_size):\n",
    "                    if preview_shown >= preview_count:\n",
    "                        break\n",
    "                    input_id = input_ids[i].cpu().numpy()\n",
    "                    text = tokenizer.decode(input_id, skip_special_tokens=True)\n",
    "                    print(f\"\\n[{name} é æ¸¬] ç¬¬ {preview_shown+1} ç­†\")\n",
    "                    print(f\"Text: {text}\")\n",
    "                    print(f\"Predicted: {label_encoder.inverse_transform([preds[i]])[0]}\")\n",
    "                    print(f\"Actual:    {label_encoder.inverse_transform([labels[i].cpu().item()])[0]}\")\n",
    "                    preview_shown += 1\n",
    "\n",
    "    print(f\"\\n{name} è©•ä¼°çµæœï¼š\")\n",
    "    print(classification_report(all_labels, all_preds, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1wqejxS910SJ"
   },
   "outputs": [],
   "source": [
    "# è³‡æ–™åˆ†å‰²ï¼šè³‡æ–™é›†åˆ‡åˆ†èˆ‡å–æ¨£\n",
    "dataset = CustomDataset(df)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "train_labels = [train_dataset[i]['labels'].item() for i in range(len(train_dataset))]\n",
    "class_counts = pd.Series(train_labels).value_counts().to_dict()\n",
    "weights = [1.0 / class_counts[label] for label in train_labels]\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# åŸ·è¡Œå¤šæ¨¡å‹è¨“ç·´\n",
    "model_variants = {\n",
    "    \"FusionMacRegressor\": FusionMacBERTRegressor(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"FusionMacBERT\": FusionMacBERTModel(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"PureMacBERT\": PureMacBERTModel(\"hfl/chinese-macbert-base\", 3),\n",
    "    \"NumericOnly\": NumericOnlyModel(len(num_cols), 3),\n",
    "    \"BiLSTMWithNumeric\": BiLSTMWithNumeric(tokenizer.vocab_size, 128, 128, len(num_cols), 3),\n",
    "    \"MacBERTWithGRU\": MacBERTWithGRU(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"MacBERTMLPFusion\": MacBERTMLPFusion(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"TextCNNMacBERT\": TextCNNMacBERT(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"RoBERTa\": FusionMacBERTModel(\"hfl/chinese-roberta-wwm-ext\", len(num_cols), 3),\n",
    "    \"BERTwwmExt\": FusionMacBERTModel(\"hfl/chinese-bert-wwm-ext\", len(num_cols), 3),\n",
    "    \"ERNIE\": FusionMacBERTModel(\"nghuyong/ernie-3.0-base-zh\", len(num_cols), 3),\n",
    "    \"ConvBERT\": FusionMacBERTModel(\"YituTech/conv-bert-base\", len(num_cols), 3)\n",
    "}\n",
    "\n",
    "# é€å€‹æ¨¡å‹è¨“ç·´èˆ‡è¼¸å‡ºçµæœ\n",
    "for name, model in model_variants.items():\n",
    "    tokenizer_name = model_tokenizer_map.get(name, default_tokenizer_name)\n",
    "    if tokenizer_name:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        encodings = tokenizer(df['content'].tolist(), truncation=True, padding='max_length', max_length=128)\n",
    "        df['input_ids'] = encodings['input_ids']\n",
    "        df['attention_mask'] = encodings['attention_mask']\n",
    "    train_and_eval(model, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8WP2MxFtLUhR"
   },
   "source": [
    "1. FusionMacBERT âœ…æ–‡å­— + âœ…æ•¸å€¼\n",
    "BERTï¼š ä½¿ç”¨ MacBERT\n",
    "æ¶æ§‹ï¼š æŠŠ [CLS] å‘é‡èˆ‡æ•¸å€¼ç‰¹å¾µç¶“é MLP èåˆ\n",
    "ç”¨é€”ï¼š åšç‚º baseline èåˆæ¨¡å‹\n",
    "å„ªé»ï¼š åŒæ™‚è€ƒæ…®å…§å®¹èªç¾©èˆ‡è²¼æ–‡çµ±è¨ˆè³‡æ–™ï¼ˆå¦‚æŒ‰è®šæ•¸ã€æ˜¯å¦æœ‰ hashtagï¼‰\n",
    "\n",
    "2. PureMacBERT âœ…æ–‡å­— + âŒæ•¸å€¼\n",
    "BERTï¼š ä½¿ç”¨ MacBERT\n",
    "æ¶æ§‹ï¼š å–®ç´”ä½¿ç”¨ [CLS]ï¼Œå¾Œæ¥ linear å±¤åˆ†é¡\n",
    "ç”¨é€”ï¼š ç´”èªè¨€æ¨¡å‹ baseline\n",
    "å°ç…§ï¼š å¯ç”¨ä¾†æ¯”è¼ƒæ˜¯å¦æœ‰æ•¸å€¼è¼”åŠ©æå‡æ•ˆæœ\n",
    "\n",
    "3. NumericOnly âŒæ–‡å­— + âœ…æ•¸å€¼\n",
    "æ¨¡å‹é¡å‹ï¼š åªæœ‰æ•¸å€¼è¼¸å…¥ï¼Œç¶“é MLP åšåˆ†é¡\n",
    "ç”¨é€”ï¼š æ¸¬è©¦ã€Œåªé è²¼æ–‡çµ±è¨ˆè³‡æ–™ã€èƒ½å¦é”åˆ°åˆç†åˆ†é¡\n",
    "å°ç…§ï¼š å¯èˆ‡æ–‡å­—æ¨¡å‹æˆ–èåˆæ¨¡å‹å°æ¯”æ•ˆæœ\n",
    "\n",
    "4. BiLSTMWithNumeric âœ…æ–‡å­—ï¼ˆEmbedding+LSTMï¼‰+ âœ…æ•¸å€¼\n",
    "åµŒå…¥æ–¹å¼ï¼š ä½¿ç”¨ nn.Embedding + BiLSTM è™•ç†æ–‡å­—ï¼ˆä¸æ˜¯ BERTï¼‰\n",
    "èåˆæ–¹å¼ï¼š å°‡ LSTM æœ€å¾Œæ™‚é–“æ­¥ + æ•¸å€¼ç‰¹å¾µæ‹¼æ¥\n",
    "ç‰¹åˆ¥é»ï¼š æ¸¬è©¦ã€Œé Transformer æ¨¡å‹ã€æ˜¯å¦ä»å…·ç«¶çˆ­åŠ›\n",
    "\n",
    "5. MacBERTWithGRU âœ…æ–‡å­—ï¼ˆMacBERTï¼‰+ âœ…æ•¸å€¼\n",
    "æ–‡å­—è™•ç†ï¼š MacBERT ä¹‹å¾Œå†ä¸² GRU\n",
    "èåˆæ–¹å¼ï¼š GRU è¼¸å‡ºæœ€å¾Œä¸€æ­¥æ‹¼æ¥æ•¸å€¼ç‰¹å¾µ\n",
    "æ„åœ–ï¼š æƒ³çœ‹ BERT+RNN çš„è¡¨ç¾ vs. å‚³çµ± BERT\n",
    "\n",
    "6. MacBERTMLPFusion âœ…æ–‡å­— + âœ…æ•¸å€¼\n",
    "è™•ç†æ–¹å¼ï¼š æ–‡å­—èˆ‡æ•¸å€¼ç›´æ¥æ‹¼æ¥å¾Œé€²å…¥ MLP\n",
    "ä¸åŒæ–¼ FusionMacBERTï¼š\n",
    "æ²’æœ‰é¡å¤–è™•ç†æ•¸å€¼ç‰¹å¾µï¼ˆå¦‚æ²’æœ‰ç¶“é nn.Linear)\n",
    "æ›´å–®ç´”çš„èåˆè¨­è¨ˆï¼ˆå±¬æ–¼ Early Fusionï¼‰\n",
    "\n",
    "7. TextCNNMacBERT âœ…æ–‡å­— + âœ…æ•¸å€¼\n",
    "æ¨¡å‹çµ„åˆï¼š\n",
    "ä½¿ç”¨ BERT ç·¨ç¢¼å¾Œä¸Ÿé€² CNN filter (TextCNN)\n",
    "å†èˆ‡æ•¸å€¼ç‰¹å¾µèåˆ\n",
    "ç”¨é€”ï¼š æ¸¬è©¦ BERT çµåˆ CNN ç‰¹å¾µæå–æ˜¯å¦æå‡æ•ˆæœ\n",
    "æœ‰è¶£é»ï¼š æœ‰äº›çŸ­æ–‡æ¨¡å‹ï¼ˆå¦‚å¾®åšã€Threadsï¼‰å° CNN ç‰¹å¾µæŠ“å–æ•æ„Ÿ\n",
    "\n",
    "8. RoBERTa âœ…æ–‡å­— + âœ…æ•¸å€¼\n",
    "BERT æ›¿ä»£å“ï¼š æ”¹ç”¨ RoBERTaï¼ˆä¸­æ–‡ç‰ˆæœ¬ï¼‰\n",
    "èåˆæ–¹å¼ï¼š åŒ FusionMacBERT\n",
    "å¯¦é©—ç›®çš„ï¼š æ¸¬è©¦ä¸åŒèªè¨€æ¨¡å‹å°çµæœçš„å½±éŸ¿ï¼ˆèªè¨€æ¨¡å‹ ablationï¼‰\n",
    "\n",
    "\n",
    "9. BERTwwmExt âœ…æ–‡å­— + âœ…æ•¸å€¼\n",
    "BERTï¼š ä½¿ç”¨ Chinese BERT whole-word-masking æ“´å±•ç‰ˆ\n",
    "æ¯”è¼ƒç›®çš„ï¼š åŒä¸Šï¼Œç”¨æ–¼æ¸¬è©¦ä¸åŒèªè¨€æ¨¡å‹ç‰¹æ€§çš„å½±éŸ¿\n",
    "\n",
    "10. ERNIE âœ…æ–‡å­— + âœ…æ•¸å€¼\n",
    "BERTï¼š æ”¹ç”¨ç™¾åº¦çš„ ERNIEï¼ˆå¼•å…¥çŸ¥è­˜å¢å¼·ï¼‰\n",
    "é©ç”¨å ´æ™¯ï¼š ç•¶æ–‡æœ¬èˆ‡å¸¸è­˜æœ‰é—œï¼ˆå¦‚è©±é¡Œã€ç”¨èªï¼‰\n",
    "ç›®çš„ï¼š è©•ä¼°çŸ¥è­˜å‹èªè¨€æ¨¡å‹åœ¨ç¤¾ç¾¤æ–‡æœ¬åˆ†é¡çš„æ•ˆæœ\n",
    "\n",
    "11. ConvBERT âœ…æ–‡å­— + âœ…æ•¸å€¼\n",
    "æ¨¡å‹ç‰¹è‰²ï¼š ä½¿ç”¨ Convolution + Self-Attention æ··åˆæ¶æ§‹çš„ BERT\n",
    "å¯¦é©—æ„ç¾©ï¼š è©¦é©—éå‚³çµ± Self-Attention æ¨¡å‹æ˜¯å¦æœ‰å„ªå‹¢\n",
    "\n",
    "\n",
    "| æ¨¡å‹åç¨±              | èªªæ˜               | æ˜¯å¦èåˆ | æ–‡æœ¬è™•ç†æ³•         | ç‰¹æ®Šè™•ç†       |\n",
    "| ----------------- | ---------------- | ---- | ------------- | ---------- |\n",
    "| FusionMacBERT     | BERT + æ•¸å€¼ç‰¹å¾µ      | âœ…    | MacBERT       | è‡ªè£½èåˆå±¤      |\n",
    "| PureMacBERT       | ç´”æ–‡æœ¬æ¨¡å‹            | âŒ    | MacBERT       | baseline   |\n",
    "| NumericOnly       | ç´”çµ±è¨ˆæ•¸å€¼            | âŒ    | ç„¡             | MLP only   |\n",
    "| BiLSTMWithNumeric | LSTM + æ•¸å€¼        | âœ…    | nn.Embedding  | ä¸ä½¿ç”¨ BERT   |\n",
    "| MacBERTWithGRU    | BERT + GRU + æ•¸å€¼  | âœ…    | MacBERT + GRU | æ™‚åºç‰¹å¾µå¼·åŒ–     |\n",
    "| MacBERTMLPFusion  | BERT + æ•¸å€¼        | âœ…    | MacBERT       | æ‹¼æ¥å¾Œé€² MLP   |\n",
    "| TextCNNMacBERT    | BERT + CNN + æ•¸å€¼  | âœ…    | MacBERT + CNN | æ¨¡ä»¿ TextCNN |\n",
    "| RoBERTa           | æ› BERT backbone  | âœ…    | RoBERTa       | æ¨¡å‹æ¯”è¼ƒ       |\n",
    "| BERTwwmExt        | æ› BERT backbone  | âœ…    | BERT-wwm      | æ¨¡å‹æ¯”è¼ƒ       |\n",
    "| ERNIE             | å¼•å…¥çŸ¥è­˜çš„ BERT       | âœ…    | ERNIE         | æ¨¡å‹æ¯”è¼ƒ       |\n",
    "| ConvBERT          | æ··åˆå·ç© + æ³¨æ„åŠ›çš„ BERT | âœ…    | ConvBERT      | æ¨¡å‹æ¯”è¼ƒ       |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OBCtDWKlz6m8"
   },
   "outputs": [],
   "source": [
    "# è³‡æ–™åˆ†å‰²ï¼šè³‡æ–™é›†åˆ‡åˆ†èˆ‡å–æ¨£\n",
    "dataset = CustomDataset(df)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, len(dataset)-train_size])\n",
    "train_labels = [train_dataset[i]['labels'].item() for i in range(len(train_dataset))]\n",
    "class_counts = pd.Series(train_labels).value_counts().to_dict()\n",
    "weights = [1.0 / class_counts[label] for label in train_labels]\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "# åŸ·è¡Œå¤šæ¨¡å‹è¨“ç·´\n",
    "model_variants = {\n",
    "    \"FusionMacBERT\": FusionMacBERTModel(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"PureMacBERT\": PureMacBERTModel(\"hfl/chinese-macbert-base\", 3),\n",
    "    \"NumericOnly\": NumericOnlyModel(len(num_cols), 3),\n",
    "    \"BiLSTMWithNumeric\": BiLSTMWithNumeric(tokenizer.vocab_size, 128, 128, len(num_cols), 3),\n",
    "    \"MacBERTWithGRU\": MacBERTWithGRU(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"MacBERTMLPFusion\": MacBERTMLPFusion(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"TextCNNMacBERT\": TextCNNMacBERT(\"hfl/chinese-macbert-base\", len(num_cols), 3),\n",
    "    \"RoBERTa\": FusionMacBERTModel(\"hfl/chinese-roberta-wwm-ext\", len(num_cols), 3),\n",
    "    \"BERTwwmExt\": FusionMacBERTModel(\"hfl/chinese-bert-wwm-ext\", len(num_cols), 3),\n",
    "    \"ERNIE\": FusionMacBERTModel(\"nghuyong/ernie-3.0-base-zh\", len(num_cols), 3),\n",
    "    \"ConvBERT\": FusionMacBERTModel(\"YituTech/conv-bert-base\", len(num_cols), 3)\n",
    "}\n",
    "\n",
    "# é€å€‹æ¨¡å‹è¨“ç·´èˆ‡è¼¸å‡ºçµæœ\n",
    "for name, model in model_variants.items():\n",
    "    tokenizer_name = model_tokenizer_map.get(name, default_tokenizer_name)\n",
    "    if tokenizer_name:\n",
    "        tokenizer = AutoTokenizer.from_pretrained(tokenizer_name)\n",
    "        encodings = tokenizer(df['content'].tolist(), truncation=True, padding='max_length', max_length=128)\n",
    "        df['input_ids'] = encodings['input_ids']\n",
    "        df['attention_mask'] = encodings['attention_mask']\n",
    "    train_and_eval(model, name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sd8HLHR6VL1"
   },
   "source": [
    "# è¿´æ­¸é æ¸¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "291iyZhHxpj9"
   },
   "outputs": [],
   "source": [
    "# åŸæœ¬é€™æ¨£åˆ†é¡ï¼ˆè¦æ‹¿æ‰ï¼‰\n",
    "# df['view_class'] = ...\n",
    "# df['label'] = ...\n",
    "\n",
    "# ç›´æ¥ç”¨åŸå§‹ view_count ä½œç‚º regression target\n",
    "df = df.dropna(subset=[\"content\", \"view_count\"])\n",
    "df['target'] = df['view_count'].apply(parse_count)  # å¦‚æœ view_count ä¸æ˜¯æ•¸å­—è¦å…ˆè½‰æ›\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "dedliSNv7UGU"
   },
   "outputs": [],
   "source": [
    "def train_and_eval_regression(model, name):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    # è¨“ç·´\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            numerics = batch['numerics'].to(device)\n",
    "            targets = batch['labels'].float().to(device)  # é‡è¦ï¼šlabels å¿…é ˆæ˜¯ float\n",
    "            preds = model(input_ids, attention_mask, numerics)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    # è©•ä¼°\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            numerics = batch['numerics'].to(device)\n",
    "            targets = batch['labels'].float().to(device)\n",
    "            preds = model(input_ids, attention_mask, numerics)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "    mse = mean_squared_error(all_targets, all_preds)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "    print(f\"\\n{name}  MSE: {mse:.2f} | MAE: {mae:.2f}| R2: {r2:.2f}\")\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "    return all_targets, all_preds\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "5c7CQi1v6wwI"
   },
   "outputs": [],
   "source": [
    "class FusionMacBERTRegressor(nn.Module):\n",
    "    def __init__(self, model_name, num_numeric_features, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.numeric_fc = nn.Linear(num_numeric_features, 64)\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size + 64, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerics):\n",
    "        cls_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        num_out = torch.relu(self.numeric_fc(numerics))\n",
    "        combined = torch.cat((cls_output, num_out), dim=1)\n",
    "        return self.regressor(self.dropout(combined)).squeeze(1)  # (batch,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "kTncOradCUz8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "rm -rf ~/.cache/huggingface/transformers/hfl__chinese-macbert-base\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ptY9GnoACUz8"
   },
   "outputs": [],
   "source": [
    "# Dataset\n",
    "'''\n",
    "class CustomDatasetRegression(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = df['input_ids'].tolist()\n",
    "        self.attention_mask = df['attention_mask'].tolist()\n",
    "        self.labels = df['label'].astype(float).values   # â† ç‚ºå›æ­¸ä»»å‹™éœ€è½‰æˆ float\n",
    "        self.numerics = df[num_cols].astype(float).values  # â† ç¢ºä¿ç‚º float array\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "            'numerics': torch.tensor(self.numerics[idx], dtype=torch.float),  # â† ä¿®æ­£ç‚º float\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float)       # â† ä¿®æ­£ç‚º float\n",
    "        }\n",
    "'''\n",
    "class CustomDatasetRegression(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.input_ids = df['input_ids'].tolist()\n",
    "        self.attention_mask = df['attention_mask'].tolist()\n",
    "        self.labels = df['target'].astype(float).values\n",
    "        self.numerics = df[num_cols].astype(float).values\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': torch.tensor(self.input_ids[idx], dtype=torch.long),\n",
    "            'attention_mask': torch.tensor(self.attention_mask[idx], dtype=torch.long),\n",
    "            'numerics': torch.tensor(self.numerics[idx], dtype=torch.float),\n",
    "            'labels': torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Loss\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0):\n",
    "        super().__init__()\n",
    "        self.gamma = gamma\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        logp = self.ce(input, target)\n",
    "        p = torch.exp(-logp)\n",
    "        loss = (1 - p) ** self.gamma * logp\n",
    "        return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Rlezwnry2K0h"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "FusionMacBERTRegressor  MSE: 4410895810.43 | MAE: 10676.62 | RÂ²: -0.03\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = CustomDatasetRegression(df)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, len(dataset) - train_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8)\n",
    "\n",
    "\n",
    "class FusionMacBERTRegressor(nn.Module):\n",
    "    def __init__(self, model_name, num_numeric_features, output_dim=1):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.numeric_fc = nn.Linear(num_numeric_features, 64)\n",
    "        self.regressor = nn.Linear(self.bert.config.hidden_size + 64, output_dim)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, numerics):\n",
    "        cls_output = self.bert(input_ids=input_ids, attention_mask=attention_mask).last_hidden_state[:, 0, :]\n",
    "        num_out = torch.relu(self.numeric_fc(numerics))\n",
    "        combined = torch.cat((cls_output, num_out), dim=1)\n",
    "        return self.regressor(self.dropout(combined)).squeeze(1)\n",
    "\n",
    "\n",
    "def train_and_eval_regression(model, name):\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(5):\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            numerics = batch['numerics'].to(device)\n",
    "            targets = batch['labels'].float().to(device)\n",
    "\n",
    "            preds = model(input_ids, attention_mask, numerics)\n",
    "            loss = loss_fn(preds, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    all_preds, all_targets = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            numerics = batch['numerics'].to(device)\n",
    "            targets = batch['labels'].float().to(device)\n",
    "\n",
    "            preds = model(input_ids, attention_mask, numerics)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "    mse = mean_squared_error(all_targets, all_preds)\n",
    "    mae = mean_absolute_error(all_targets, all_preds)\n",
    "    r2 = r2_score(all_targets, all_preds)\n",
    "\n",
    "    print(f\"\\n{name}  MSE: {mse:.2f} | MAE: {mae:.2f} | RÂ²: {r2:.2f}\")\n",
    "    return all_targets, all_preds\n",
    "\n",
    "\n",
    "model = FusionMacBERTRegressor(\"hfl/chinese-macbert-base\", len(num_cols))\n",
    "all_targets, all_preds = train_and_eval_regression(model, \"FusionMacBERTRegressor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bQwvt6LQ10Pi"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RF-tbCHU10Ea"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EmUJQfroFBqt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yEyKqKjE9oZy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6OeqnHopFJuT"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q0DyH1z7FJm3"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnoabF2fFJgR"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LaucnuMEFCV-"
   },
   "source": [
    "#**ä¸‹é¢éƒ½æ˜¯èˆŠçš„æ±è¥¿è€Œå·²~~~~**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qvuTn85bUTA5"
   },
   "outputs": [],
   "source": [
    "stopwords = set(['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'ä¹Ÿ', 'èˆ‡', 'æœ‰', 'ç‚º', 'ç­‰'])\n",
    "\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    words = jieba.cut(text)\n",
    "    words_filtered = [word for word in words if word not in stopwords]\n",
    "    return ' '.join(words_filtered)\n",
    "\n",
    "df['processed_content'] = df['Content'].apply(tokenize_and_remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nzhynZN7IYy"
   },
   "source": [
    "new_article = \"IC è¨­è¨ˆå¤§å» è¯ç™¼ç§‘ (2454-TW) å‰¯è‘£äº‹é•·æš¨åŸ·è¡Œé•·è”¡åŠ›è¡Œä»Š (26) æ—¥ç²é ’æ½˜æ–‡æ·µçï¼Œæœƒå¾Œå—è¨ªè¡¨ç¤ºï¼Œè¯ç™¼ç§‘ 3 å¥ˆç±³æœƒåœ¨å°ç©é›» (2330-TW)(TSM-US) åšï¼Œä¸”ç”±æ–¼å…ˆé€²è£½ç¨‹æŠ€è¡“ç›¸ç•¶è¤‡é›œï¼Œä¸è«–è¦æ¡ç”¨æˆ–æ›´æ›éƒ½éå¸¸å›°é›£ï¼Œé›™æ–¹æœƒæŒçºŒç·Šå¯†åˆä½œã€‚å¤–ç•Œä»Šæ—¥æå•ä¸è«–æ˜¯è¼é” (NVDA-US)ã€è˜‹æœ (AAPL-US) ç­‰éƒ½è¡¨ç¤ºå°‹æ±‚å¤šå…ƒçš„æ™¶åœ“ä»£å·¥æ–¹æ¡ˆï¼Œè”¡åŠ›è¡Œå›æ‡‰ï¼Œè¯ç™¼ç§‘åœ¨å…ˆé€²è£½ç¨‹æŒçºŒèˆ‡å°ç©é›»ç·Šå¯†åˆä½œï¼Œè‹±ç‰¹çˆ¾ (INTC-US) å‰‡è² è²¬ 16 å¥ˆç±³è”¡åŠ›è¡Œä¹Ÿå¼·èª¿ï¼Œè¯ç™¼ç§‘ä¸æœƒåªåœåœ¨æ¡ç”¨ 4 å¥ˆç±³ï¼Œä¹Ÿæœƒæ¡ç”¨ 3 å¥ˆç±³è£½ç¨‹ï¼Œæ­¤å¤–ï¼Œç”±æ–¼é›»æ™¶é«”å¾®ç¸®é€Ÿåº¦è¶¨ç·©ï¼Œå„˜ç®¡æŠ€è¡“ä¸Šå¯è¡Œï¼Œä½†ä¸ä¸€å®šç¬¦åˆç¶“æ¿Ÿæ•ˆç›Šï¼Œå› æ­¤æŠ€è¡“ä¹Ÿé€æ­¥å¾å¹³é¢è®Šæˆ 2Dã€2.5Dï¼Œç”šè‡³ 3D ç­‰ï¼Œå…ˆé€²å°è£çš„é‡è¦æ€§æ¯”ä»¥å‰å¢åŠ ã€‚è‡³æ–¼è·Ÿè¼é”åˆä½œï¼Œè”¡åŠ›è¡Œé‡ç”³ï¼Œé›™æ–¹åˆä½œä»ä»¥æ±½è»Šç‚ºä¸»ï¼Œè¼é”å¸ƒå±€è»Šç”¨æ¯”è¯ç™¼ç§‘æ—©ï¼Œä¸»è¦è‘—å¢¨åœ¨æ™ºæ…§åº§è‰™èˆ‡ ADAS ç³»çµ±ï¼Œé›™æ–¹æœ‰å¾ˆå¥½çš„é…åˆï¼Œå…¶ä¸­ï¼Œè¼é”ä¸»æ”»é«˜éšã€è¯ç™¼ç§‘å‰‡ç„æº–ä¸­éšï¼Œé›™æ–¹æ­£å¯†åˆ‡åˆä½œé–‹æœƒã€‚\"\n",
    "processed_new_article = tokenize_and_remove_stopwords(new_article)\n",
    "\n",
    "# Random Forest æ¨¡å‹è¨“ç·´èˆ‡é æ¸¬\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# ä½¿ç”¨ç›¸åŒçš„æ•¸æ“šåˆ†å‰²æ–¹å¼\n",
    "X_train_rf, X_val_rf, y_train_rf, y_val_rf = train_test_split(tfidf_matrix, y, test_size=0.1, random_state=42)\n",
    "\n",
    "X_train_rf, X_val_rf, y_train_rf, y_val_rf = train_test_split(X_train_rf, y_train_rf, test_size=0.1, random_state=42)\n",
    "\n",
    "# å‰µå»ºéš¨æ©Ÿæ£®æ—æ¨¡å‹\n",
    "rand_forest_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# è¨“ç·´éš¨æ©Ÿæ£®æ—æ¨¡å‹\n",
    "rand_forest_model.fit(X_train_rf, y_train_rf)\n",
    "\n",
    "# é æ¸¬\n",
    "y_val_pred_rf = rand_forest_model.predict(X_val_rf)\n",
    "y_test_pred_rf = rand_forest_model.predict(X_test)\n",
    "\n",
    "# åˆ†é¡å ±å‘Š\n",
    "print(\"é©—è­‰é›† Validation Classification Report:\")\n",
    "print(classification_report(y_val_rf, y_val_pred_rf))\n",
    "\n",
    "print(\"\\næ¸¬è©¦é›† Test Classification Report:\")\n",
    "print(classification_report(y_test, y_test_pred_rf))\n",
    "\n",
    "# å°ç…§è¡¨\n",
    "result_df_val_rf = pd.DataFrame({'Actual': y_val_rf, 'Predicted': y_val_pred_rf})\n",
    "result_df_test_rf = pd.DataFrame({'Actual': y_test, 'Predicted': y_test_pred_rf})\n",
    "\n",
    "print(\"é©—è­‰é›† Validation Result Comparison:\")\n",
    "print(result_df_val_rf)\n",
    "\n",
    "print(\"\\næ¸¬è©¦é›† Test Result Comparison:\")\n",
    "print(result_df_test_rf)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VTn9buro9xlD"
   },
   "outputs": [],
   "source": [
    "new_article = \"IC è¨­è¨ˆå¤§å» è¯ç™¼ç§‘ (2454-TW) å‰¯è‘£äº‹é•·æš¨åŸ·è¡Œé•·è”¡åŠ›è¡Œä»Š (26) æ—¥ç²é ’æ½˜æ–‡æ·µçï¼Œæœƒå¾Œå—è¨ªè¡¨ç¤ºï¼Œè¯ç™¼ç§‘ 3 å¥ˆç±³æœƒåœ¨å°ç©é›» (2330-TW)(TSM-US) åšï¼Œä¸”ç”±æ–¼å…ˆé€²è£½ç¨‹æŠ€è¡“ç›¸ç•¶è¤‡é›œï¼Œä¸è«–è¦æ¡ç”¨æˆ–æ›´æ›éƒ½éå¸¸å›°é›£ï¼Œé›™æ–¹æœƒæŒçºŒç·Šå¯†åˆä½œã€‚å¤–ç•Œä»Šæ—¥æå•ä¸è«–æ˜¯è¼é” (NVDA-US)ã€è˜‹æœ (AAPL-US) ç­‰éƒ½è¡¨ç¤ºå°‹æ±‚å¤šå…ƒçš„æ™¶åœ“ä»£å·¥æ–¹æ¡ˆï¼Œè”¡åŠ›è¡Œå›æ‡‰ï¼Œè¯ç™¼ç§‘åœ¨å…ˆé€²è£½ç¨‹æŒçºŒèˆ‡å°ç©é›»ç·Šå¯†åˆä½œï¼Œè‹±ç‰¹çˆ¾ (INTC-US) å‰‡è² è²¬ 16 å¥ˆç±³è”¡åŠ›è¡Œä¹Ÿå¼·èª¿ï¼Œè¯ç™¼ç§‘ä¸æœƒåªåœåœ¨æ¡ç”¨ 4 å¥ˆç±³ï¼Œä¹Ÿæœƒæ¡ç”¨ 3 å¥ˆç±³è£½ç¨‹ï¼Œæ­¤å¤–ï¼Œç”±æ–¼é›»æ™¶é«”å¾®ç¸®é€Ÿåº¦è¶¨ç·©ï¼Œå„˜ç®¡æŠ€è¡“ä¸Šå¯è¡Œï¼Œä½†ä¸ä¸€å®šç¬¦åˆç¶“æ¿Ÿæ•ˆç›Šï¼Œå› æ­¤æŠ€è¡“ä¹Ÿé€æ­¥å¾å¹³é¢è®Šæˆ 2Dã€2.5Dï¼Œç”šè‡³ 3D ç­‰ï¼Œå…ˆé€²å°è£çš„é‡è¦æ€§æ¯”ä»¥å‰å¢åŠ ã€‚è‡³æ–¼è·Ÿè¼é”åˆä½œï¼Œè”¡åŠ›è¡Œé‡ç”³ï¼Œé›™æ–¹åˆä½œä»ä»¥æ±½è»Šç‚ºä¸»ï¼Œè¼é”å¸ƒå±€è»Šç”¨æ¯”è¯ç™¼ç§‘æ—©ï¼Œä¸»è¦è‘—å¢¨åœ¨æ™ºæ…§åº§è‰™èˆ‡ ADAS ç³»çµ±ï¼Œé›™æ–¹æœ‰å¾ˆå¥½çš„é…åˆï¼Œå…¶ä¸­ï¼Œè¼é”ä¸»æ”»é«˜éšã€è¯ç™¼ç§‘å‰‡ç„æº–ä¸­éšï¼Œé›™æ–¹æ­£å¯†åˆ‡åˆä½œé–‹æœƒã€‚\"\n",
    "\n",
    "processed_new_article = tokenize_and_remove_stopwords(new_article)\n",
    "\n",
    "print(processed_new_article)\n",
    "\n",
    "# å°‡æ–°æ–‡ç« è½‰æ›ç‚º TF-IDF è¡¨ç¤ºå½¢å¼\n",
    "new_article_tfidf = tfidf_vectorizer.transform([processed_new_article])\n",
    "\n",
    "# ä½¿ç”¨æŠ•ç¥¨åˆ†é¡å™¨é€²è¡Œé æ¸¬\n",
    "predicted_label_ensemble = voting_classifier.predict(new_article_tfidf)\n",
    "\n",
    "print(f\"æ–°æ–‡ç« é æ¸¬çµæœ: {predicted_label_ensemble}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SjsKVnf0-iiU"
   },
   "outputs": [],
   "source": [
    "# ä½¿ç”¨ inverse_transform å°‡é æ¸¬çš„æ•¸å­—ç·¨ç¢¼è½‰æ›å›åŸå§‹æ¨™ç±¤\n",
    "predicted_label_original = label_encoder.inverse_transform(predicted_label_ensemble)\n",
    "\n",
    "print(f\"æ–°æ–‡ç« é æ¸¬çµæœï¼ˆåŸå§‹æ¨™ç±¤ï¼‰: {predicted_label_original}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yMJI_upxwRgP"
   },
   "source": [
    "## å¯¦éš›é æ¸¬ï¼ˆç ”ç©¶ï¼‰\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9gbdm9r7_qFq"
   },
   "outputs": [],
   "source": [
    "# ç²å–æ‰€æœ‰æ¨™ç±¤å°æ‡‰çš„ç·¨ç¢¼\n",
    "all_labels = label_encoder.classes_\n",
    "\n",
    "print(\"æ‰€æœ‰æ¨™ç±¤å°æ‡‰çš„ç·¨ç¢¼:\")\n",
    "for label_code, label in enumerate(all_labels):\n",
    "    print(f\"ç·¨ç¢¼ {label_code}: æ¨™ç±¤ {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rTk9I4ZtEPBP"
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "# å®šç¾©åœç”¨è©\n",
    "stopwords = set(['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'ä¹Ÿ', 'èˆ‡', 'æœ‰', 'ç‚º', 'ç­‰'])\n",
    "\n",
    "# å®šç¾©åˆ†è©ä¸¦å»é™¤åœç”¨è©çš„å‡½æ•¸\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    words = jieba.cut(text)  # ä½¿ç”¨ jieba è¿›è¡Œåˆ†è¯\n",
    "    words_filtered = [word for word in words if word not in stopwords]  # å»é™¤åœç”¨è¯\n",
    "    return ' '.join(words_filtered)\n",
    "\n",
    "# å°‡è™•ç†å¾Œçš„å…§å®¹åŠ å…¥ DataFrame ä¸­\n",
    "df['processed_content'] = df['Content'].apply(tokenize_and_remove_stopwords)\n",
    "\n",
    "# æ–°æ–‡ç« \n",
    "new_article = \"å°è‚¡å®ˆç©©å­£ç·šï¼Œé€±ç·šä¸‰é€£ç´…ã€‚ï¼ˆè³‡æ–™ç…§ï¼‰ ã€”è²¡ç¶“é »é“ï¼ç¶œåˆå ±å°ã€•ç¾åœ‹CPIç•¥é«˜æ–¼å¸‚å ´é æœŸï¼Œç¾è‚¡æ¼²å‹¢æš«æ­‡ï¼Œæœ¬é€±ä»¥ä¾†ï¼Œå°è‚¡ç¶“éå…©æ—¥å¤§æ¼²å¾Œï¼Œä»Šï¼ˆ13ï¼‰æ—¥æŒ‡æ•¸éœ‡ç›ªèµ°ä½ï¼Œçµ‚å ´ä¸‹è·Œ43.34é»ï¼Œä»¥16782.57é»ä½œæ”¶ï¼Œå®ˆä½å­£ç·šé—œå¡ï¼Œæˆäº¤é‡ç‚º2986.08å„„å…ƒï¼Œé€±ç·šä¸Šæ¼²262é»ï¼Œå‘ˆç¾ä¸‰é€£ç´…ï¼Œç·¯å‰µå¤±å®ˆç™¾å…ƒå¤§é—œï¼ŒAIæ—ç¾¤æ™®ééƒ½æ˜¯æ”¶é»‘ï¼Œé›»å­é¡è‚¡ä»¥çŸ½å…‰å­ã€ç¶²é€šç­‰æ¬¡æ—ç¾¤æ¯”è¼ƒæœ‰è¡¨ç¾ï¼Œå‚³ç”¢è¼ªå‹•åˆ°ç‡Ÿå»ºã€é€ ç´™ã€ç™¾è²¨ç­‰æ¥æ£’æ¼”å‡ºã€‚ å‰10å¤§æˆäº¤é¡å€‹è‚¡æ¼²å¤šè·Œå°‘ï¼Œé™¤äº†AIæ—ç¾¤æ”¶é»‘ï¼Œå…¶ä»–éƒ½æ˜¯ç´…ç›¤å±…å¤šï¼Œå»£é”è·Œ12å…ƒï¼Œæ”¶226å…ƒï¼Œæˆäº¤é¡182.32å„„å…ƒï¼Œæ’åç¬¬1ï¼›å°ç©é›»çµ‚å ´æ¼²3å…ƒï¼Œæ”¶553å…ƒï¼Œæˆäº¤é¡171.29å„„å…ƒï¼Œæ’åç¬¬2ï¼›çŸ½çµ±çµ‚å ´æ¼²2.75å…ƒï¼Œæ”¶47.7å…ƒï¼Œæˆäº¤é¡146.25å„„å…ƒï¼Œæ’åç¬¬3ï¼›å®šç©æŠ•æ§æ¼²3.3å…ƒï¼Œæ”¶103å…ƒï¼Œæˆäº¤é¡95.92å„„å…ƒï¼Œæ’åç¬¬4ï¼›ç·¯å‰µè·Œ3.4å…ƒï¼Œæ”¶99.1å…ƒï¼Œæˆäº¤é¡93.89å„„å…ƒï¼Œæ’åç¬¬5ã€‚ è«‹ç¹¼çºŒå¾€ä¸‹é–±è®€...  æŠ€å˜‰è·Œ13.5å…ƒï¼Œæ”¶271å…ƒï¼Œæˆäº¤é¡89.05å„„å…ƒï¼Œæ’åç¬¬6ï¼›å‰µæ„æ”¶1695å…ƒå¹³ç›¤ï¼Œæˆäº¤é¡86.78å„„å…ƒï¼Œæ’åç¬¬7ï¼›è¯ç™¼ç§‘ä¸Šæ¼²27å…ƒï¼Œæ”¶842å…ƒï¼Œæˆäº¤é¡81.63å„„å…ƒï¼Œæ’åç¬¬8ï¼›è£•éš†æ¼²1.1å…ƒï¼Œæ”¶85.1å…ƒï¼Œæˆäº¤é¡66.51å„„å…ƒï¼Œæ’åç¬¬9ï¼›ææ–™-KYæ¼² 5å…ƒï¼Œæ”¶1185å…ƒï¼Œæˆäº¤é¡63.34å„„å…ƒï¼Œæ’åç¬¬10ã€‚ ä¸€æ‰‹æŒæ¡ç¶“æ¿Ÿè„ˆå‹•é»æˆ‘è¨‚é–±è‡ªç”±è²¡ç¶“Youtubeé »é“ ä¸ç”¨æŠ½ ä¸ç”¨æ¶ ç¾åœ¨ç”¨APPçœ‹æ–°è ä¿è­‰å¤©å¤©ä¸­çé»æˆ‘ä¸‹è¼‰APPæŒ‰æˆ‘çœ‹æ´»å‹•è¾¦æ³• ç›¸é—œæ–°è\"\n",
    "\n",
    "# è™•ç†æ–°æ–‡ç« \n",
    "processed_new_article = tokenize_and_remove_stopwords(new_article)\n",
    "\n",
    "# è¼¸å‡ºè™•ç†å¾Œçš„æ–‡ç« \n",
    "print(processed_new_article)\n",
    "\n",
    "# å°‡æ–°æ–‡ç« è½‰æ›ç‚º TF-IDF è¡¨ç¤ºå½¢å¼\n",
    "new_article_tfidf = tfidf_vectorizer.transform([processed_new_article])\n",
    "\n",
    "# ä½¿ç”¨æŠ•ç¥¨åˆ†é¡å™¨é€²è¡Œé æ¸¬\n",
    "predicted_label_ensemble = voting_classifier.predict(new_article_tfidf)\n",
    "\n",
    "# è¼¸å‡ºé æ¸¬çµæœ\n",
    "print(f\"æ–°æ–‡ç« é æ¸¬çµæœ: {predicted_label_ensemble}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wzB1yP1GFFki"
   },
   "outputs": [],
   "source": [
    "import jieba\n",
    "\n",
    "# å®šç¾©åœç”¨è©\n",
    "stopwords = set(['çš„', 'äº†', 'åœ¨', 'æ˜¯', 'å’Œ', 'ä¹Ÿ', 'èˆ‡', 'æœ‰', 'ç‚º', 'ç­‰'])\n",
    "\n",
    "# å®šç¾©åˆ†è©ä¸¦å»é™¤åœç”¨è©çš„å‡½æ•¸\n",
    "def tokenize_and_remove_stopwords(text):\n",
    "    words = jieba.cut(text)  # ä½¿ç”¨ jieba è¿›è¡Œåˆ†è¯\n",
    "    words_filtered = [word for word in words if word not in stopwords]  # å»é™¤åœç”¨è¯\n",
    "    return ' '.join(words_filtered)\n",
    "\n",
    "# å°‡è™•ç†å¾Œçš„å…§å®¹åŠ å…¥ DataFrame ä¸­\n",
    "df['processed_content'] = df['Content'].apply(tokenize_and_remove_stopwords)\n",
    "\n",
    "# æ–°æ–‡ç« \n",
    "new_article = \"å°æ¼²\"\n",
    "\n",
    "# è™•ç†æ–°æ–‡ç« \n",
    "processed_new_article = tokenize_and_remove_stopwords(new_article)\n",
    "\n",
    "# è¼¸å‡ºè™•ç†å¾Œçš„æ–‡ç« \n",
    "print(processed_new_article)\n",
    "\n",
    "# å°‡æ–°æ–‡ç« è½‰æ›ç‚º TF-IDF è¡¨ç¤ºå½¢å¼\n",
    "new_article_tfidf = tfidf_vectorizer.transform([processed_new_article])\n",
    "\n",
    "# ä½¿ç”¨æŠ•ç¥¨åˆ†é¡å™¨é€²è¡Œé æ¸¬\n",
    "predicted_label_ensemble = voting_classifier.predict(new_article_tfidf)\n",
    "\n",
    "# è¼¸å‡ºé æ¸¬çµæœ\n",
    "print(f\"æ–°æ–‡ç« é æ¸¬çµæœ: {predicted_label_ensemble}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
